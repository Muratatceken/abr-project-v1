{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üß† ABR CVAE Training & Evaluation - Google Colab\n",
        "\n",
        "**Complete training and evaluation environment for ABR CVAE project in Google Colab**\n",
        "\n",
        "## üéØ Features:\n",
        "- **Uses Existing Project**: Works with your current train.py, evaluate.py, and src/ files\n",
        "- **Google Drive Storage**: Saves results to `/content/drive/MyDrive/abr_project/`\n",
        "- **Real-time Monitoring**: Live training progress visualization\n",
        "- **No New Files**: Uses only your existing project structure\n",
        "\n",
        "## üìã Setup Instructions:\n",
        "1. Upload your entire project to Google Drive at `/MyDrive/abr_project/`\n",
        "2. Run all cells in order\n",
        "3. Use the quick functions at the bottom to train and evaluate\n",
        "\n",
        "---\n",
        "*Murat At√ßeken - ABR CVAE Project*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß Environment Setup v1\n",
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "# Check if running in Colab\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    print(\"üîç Running in Google Colab\")\n",
        "    \n",
        "    # Mount Google Drive\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "    \n",
        "    # Project paths\n",
        "    DRIVE_PROJECT_PATH = \"/content/drive/MyDrive/abr_project\"\n",
        "    LOCAL_PROJECT_PATH = \"/content/abr_project\"\n",
        "    \n",
        "except ImportError:\n",
        "    IN_COLAB = False\n",
        "    print(\"üîç Running locally\")\n",
        "    LOCAL_PROJECT_PATH = os.getcwd()\n",
        "    DRIVE_PROJECT_PATH = None\n",
        "\n",
        "print(f\"‚úÖ Environment detected: {'Colab' if IN_COLAB else 'Local'}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìÅ Project Setup - Find project in Colab environment\n",
        "if IN_COLAB:\n",
        "    # Check multiple possible locations for the cloned project\n",
        "    possible_paths = [\n",
        "        \"/content/abr-project-v1\",  # Common clone name\n",
        "        \"/content/abr_project\",     # Alternative name\n",
        "        \"/content/abr-cvae-project\", # Another alternative\n",
        "        DRIVE_PROJECT_PATH,         # Google Drive location\n",
        "    ]\n",
        "    \n",
        "    # Also check for any directory containing train.py\n",
        "    content_dirs = [d for d in os.listdir('/content') if os.path.isdir(f'/content/{d}')]\n",
        "    for dir_name in content_dirs:\n",
        "        dir_path = f'/content/{dir_name}'\n",
        "        if os.path.exists(f'{dir_path}/train.py'):\n",
        "            possible_paths.insert(0, dir_path)  # Add to front of list\n",
        "    \n",
        "    project_found = False\n",
        "    for path in possible_paths:\n",
        "        if os.path.exists(f\"{path}/train.py\"):\n",
        "            LOCAL_PROJECT_PATH = path\n",
        "            project_found = True\n",
        "            print(f\"‚úÖ Project found at: {LOCAL_PROJECT_PATH}\")\n",
        "            break\n",
        "    \n",
        "    if not project_found:\n",
        "        print(\"‚ùå Project not found in any expected location!\")\n",
        "        print(\"üîç Searched locations:\")\n",
        "        for path in possible_paths:\n",
        "            print(f\"  - {path}\")\n",
        "        print(\"\\nüí° Solutions:\")\n",
        "        print(\"1. Clone your repository: !git clone <your-repo-url>\")\n",
        "        print(\"2. Upload to Google Drive at: /MyDrive/abr_project\")\n",
        "        print(\"üìã Required files: train.py, evaluate.py, src/, configs/, data/\")\n",
        "        \n",
        "        # List current content directory to help debug\n",
        "        print(f\"\\nüìÅ Current /content directory contents:\")\n",
        "        for item in os.listdir('/content'):\n",
        "            item_path = f'/content/{item}'\n",
        "            if os.path.isdir(item_path):\n",
        "                print(f\"  üìÇ {item}/\")\n",
        "                # Check if it might be the project\n",
        "                if os.path.exists(f'{item_path}/train.py'):\n",
        "                    print(f\"    ‚úÖ Contains train.py - This might be your project!\")\n",
        "            else:\n",
        "                print(f\"  üìÑ {item}\")\n",
        "        \n",
        "        raise FileNotFoundError(\"Project files not found\")\n",
        "    \n",
        "    # Set working directory\n",
        "    os.chdir(LOCAL_PROJECT_PATH)\n",
        "    sys.path.insert(0, LOCAL_PROJECT_PATH)\n",
        "    \n",
        "else:\n",
        "    sys.path.insert(0, LOCAL_PROJECT_PATH)\n",
        "\n",
        "print(f\"üìÇ Working directory: {os.getcwd()}\")\n",
        "print(\"‚úÖ Project setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üì¶ Install Dependencies\n",
        "if IN_COLAB:\n",
        "    print(\"üì¶ Installing dependencies for Colab...\")\n",
        "    !pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "    !pip install PyYAML scipy scikit-learn matplotlib seaborn tqdm tensorboard openpyxl\n",
        "else:\n",
        "    print(\"üì¶ Installing from requirements.txt...\")\n",
        "    if os.path.exists(\"requirements.txt\"):\n",
        "        !pip install -r requirements.txt\n",
        "\n",
        "print(\"‚úÖ Dependencies installed!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ Import Libraries and Setup\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import yaml\n",
        "import json\n",
        "import subprocess\n",
        "import time\n",
        "import re\n",
        "from datetime import datetime\n",
        "from IPython.display import clear_output\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# GPU setup and optimization\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üöÄ Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üìä GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    \n",
        "    # GPU optimizations\n",
        "    torch.backends.cudnn.benchmark = True  # Optimize for consistent input sizes\n",
        "    torch.backends.cudnn.deterministic = False  # Allow non-deterministic for speed\n",
        "    \n",
        "    # Clear GPU cache\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Check GPU memory usage\n",
        "    allocated = torch.cuda.memory_allocated(0) / 1e9\n",
        "    cached = torch.cuda.memory_reserved(0) / 1e9\n",
        "    print(f\"üìà GPU Memory - Allocated: {allocated:.2f} GB, Cached: {cached:.2f} GB\")\n",
        "    \n",
        "    # Set memory fraction to avoid OOM\n",
        "    torch.cuda.set_per_process_memory_fraction(0.9)\n",
        "    \n",
        "    print(\"‚úÖ GPU optimizations applied!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è CUDA not available! Training will be very slow on CPU.\")\n",
        "    print(\"üí° Make sure to enable GPU in Colab: Runtime > Change runtime type > GPU\")\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üìä Enhanced Training Monitor with Real-time Epoch Progress\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "class TrainingMonitor:\n",
        "    def __init__(self, total_epochs=None):\n",
        "        self.metrics = {\n",
        "            'train_loss': [], 'val_loss': [], 'kl_loss': [], 'recon_loss': [], \n",
        "            'beta': [], 'epochs': []\n",
        "        }\n",
        "        self.current_epoch = 0\n",
        "        self.total_epochs = total_epochs\n",
        "        self.best_val_loss = float('inf')\n",
        "        self.start_time = time.time()\n",
        "        \n",
        "        # Current epoch metrics\n",
        "        self.current_train_loss = None\n",
        "        self.current_val_loss = None\n",
        "        self.current_kl_loss = None\n",
        "        self.current_recon_loss = None\n",
        "        self.current_beta = None\n",
        "        \n",
        "        # Track what we've already printed to avoid duplicates\n",
        "        self.last_printed_epoch = 0\n",
        "        self.epoch_results_printed = False\n",
        "        \n",
        "        # Progress bars\n",
        "        self.main_pbar = None  # Overall training progress\n",
        "        self.epoch_pbar = None  # Current epoch progress\n",
        "        \n",
        "        # Initialize main progress bar\n",
        "        if total_epochs:\n",
        "            self.main_pbar = tqdm(total=total_epochs, desc=\"üöÄ Training\", \n",
        "                                position=0, leave=True,\n",
        "                                bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}] Best: {postfix}')\n",
        "        else:\n",
        "            self.main_pbar = tqdm(desc=\"üöÄ Training\", position=0, leave=True,\n",
        "                                bar_format='{desc}: {n} epochs [{elapsed}] Best: {postfix}')\n",
        "        \n",
        "    def parse_log_line(self, line):\n",
        "        try:\n",
        "            # Parse epoch information\n",
        "            if 'Epoch' in line and ('/' in line or ':' in line):\n",
        "                epoch_match = re.search(r'Epoch (\\d+)', line)\n",
        "                if epoch_match:\n",
        "                    new_epoch = int(epoch_match.group(1))\n",
        "                    if new_epoch > self.current_epoch:\n",
        "                        # Close previous epoch progress bar\n",
        "                        if self.epoch_pbar:\n",
        "                            self.epoch_pbar.close()\n",
        "                        \n",
        "                        self.current_epoch = new_epoch\n",
        "                        self.main_pbar.n = self.current_epoch\n",
        "                        self.epoch_results_printed = False  # Reset for new epoch\n",
        "                        \n",
        "                        # Create new epoch progress bar\n",
        "                        self.epoch_pbar = tqdm(total=100, desc=f\"üìä Epoch {self.current_epoch}\", \n",
        "                                             position=1, leave=False,\n",
        "                                             bar_format='{desc}: {percentage:3.0f}%|{bar}| {postfix}')\n",
        "                        \n",
        "                        # Reset current metrics for new epoch\n",
        "                        self.current_train_loss = None\n",
        "                        self.current_val_loss = None\n",
        "                        self.current_kl_loss = None\n",
        "                        self.current_recon_loss = None\n",
        "                        self.current_beta = None\n",
        "                    \n",
        "            # Parse training loss\n",
        "            train_patterns = [r'Train Loss: ([\\d.]+)', r'Training Loss: ([\\d.]+)', r'train_loss: ([\\d.]+)']\n",
        "            for pattern in train_patterns:\n",
        "                match = re.search(pattern, line)\n",
        "                if match:\n",
        "                    self.current_train_loss = float(match.group(1))\n",
        "                    self.metrics['train_loss'].append(self.current_train_loss)\n",
        "                    # Update epoch progress bar to ~50% when training loss is available\n",
        "                    if self.epoch_pbar:\n",
        "                        self.epoch_pbar.n = 50\n",
        "                        self.update_epoch_progress()\n",
        "                    break\n",
        "                    \n",
        "            # Parse validation loss\n",
        "            val_patterns = [r'Val Loss: ([\\d.]+)', r'Validation Loss: ([\\d.]+)', r'val_loss: ([\\d.]+)']\n",
        "            for pattern in val_patterns:\n",
        "                match = re.search(pattern, line)\n",
        "                if match:\n",
        "                    self.current_val_loss = float(match.group(1))\n",
        "                    self.metrics['val_loss'].append(self.current_val_loss)\n",
        "                    if self.current_val_loss < self.best_val_loss:\n",
        "                        self.best_val_loss = self.current_val_loss\n",
        "                    \n",
        "                    # Complete epoch progress bar when validation loss is available\n",
        "                    if self.epoch_pbar:\n",
        "                        self.epoch_pbar.n = 100\n",
        "                        self.update_epoch_progress()\n",
        "                        # Close epoch bar after a brief moment\n",
        "                        self.epoch_pbar.close()\n",
        "                        self.epoch_pbar = None\n",
        "                    \n",
        "                    # Update main progress bar\n",
        "                    self.update_main_progress_bar()\n",
        "                    \n",
        "                    # Print summary if new best (only once per epoch)\n",
        "                    if not self.epoch_results_printed and self.current_epoch > self.last_printed_epoch:\n",
        "                        if self.current_val_loss == self.best_val_loss:\n",
        "                            tqdm.write(f\"   ‚≠ê NEW BEST! Val Loss: {self.best_val_loss:.4f}\")\n",
        "                        self.epoch_results_printed = True\n",
        "                        self.last_printed_epoch = self.current_epoch\n",
        "                    break\n",
        "                    \n",
        "            # Parse KL loss\n",
        "            kl_patterns = [r'KL Loss: ([\\d.]+)', r'KL: ([\\d.]+)', r'kl_loss: ([\\d.]+)']\n",
        "            for pattern in kl_patterns:\n",
        "                match = re.search(pattern, line)\n",
        "                if match:\n",
        "                    self.current_kl_loss = float(match.group(1))\n",
        "                    self.metrics['kl_loss'].append(self.current_kl_loss)\n",
        "                    # Update epoch progress when KL loss is available\n",
        "                    if self.epoch_pbar:\n",
        "                        self.update_epoch_progress()\n",
        "                    break\n",
        "                    \n",
        "            # Parse reconstruction loss\n",
        "            recon_patterns = [r'Recon Loss: ([\\d.]+)', r'Reconstruction Loss: ([\\d.]+)', r'recon_loss: ([\\d.]+)', r'Recon: ([\\d.]+)']\n",
        "            for pattern in recon_patterns:\n",
        "                match = re.search(pattern, line)\n",
        "                if match:\n",
        "                    self.current_recon_loss = float(match.group(1))\n",
        "                    self.metrics['recon_loss'].append(self.current_recon_loss)\n",
        "                    # Update epoch progress when recon loss is available\n",
        "                    if self.epoch_pbar:\n",
        "                        self.update_epoch_progress()\n",
        "                    break\n",
        "                    \n",
        "            # Parse beta\n",
        "            beta_patterns = [r'Beta: ([\\d.]+)', r'beta: ([\\d.]+)']\n",
        "            for pattern in beta_patterns:\n",
        "                match = re.search(pattern, line)\n",
        "                if match:\n",
        "                    self.current_beta = float(match.group(1))\n",
        "                    self.metrics['beta'].append(self.current_beta)\n",
        "                    # Update epoch progress when beta is available\n",
        "                    if self.epoch_pbar:\n",
        "                        self.update_epoch_progress()\n",
        "                    break\n",
        "                    \n",
        "        except:\n",
        "            pass\n",
        "    \n",
        "    def update_epoch_progress(self):\n",
        "        \"\"\"Update current epoch progress bar with real-time metrics\"\"\"\n",
        "        if not self.epoch_pbar:\n",
        "            return\n",
        "            \n",
        "        postfix_parts = []\n",
        "        if self.current_train_loss is not None:\n",
        "            postfix_parts.append(f\"Train: {self.current_train_loss:.4f}\")\n",
        "        if self.current_val_loss is not None:\n",
        "            postfix_parts.append(f\"Val: {self.current_val_loss:.4f}\")\n",
        "        if self.current_kl_loss is not None:\n",
        "            postfix_parts.append(f\"KL: {self.current_kl_loss:.4f}\")\n",
        "        if self.current_recon_loss is not None:\n",
        "            postfix_parts.append(f\"Recon: {self.current_recon_loss:.4f}\")\n",
        "        if self.current_beta is not None:\n",
        "            postfix_parts.append(f\"Beta: {self.current_beta:.4f}\")\n",
        "        \n",
        "        postfix_str = \" | \".join(postfix_parts) if postfix_parts else \"Processing...\"\n",
        "        self.epoch_pbar.set_postfix_str(postfix_str)\n",
        "        self.epoch_pbar.refresh()\n",
        "    \n",
        "    def update_main_progress_bar(self):\n",
        "        \"\"\"Update main training progress bar\"\"\"\n",
        "        if not self.main_pbar:\n",
        "            return\n",
        "            \n",
        "        if self.best_val_loss != float('inf'):\n",
        "            self.main_pbar.set_postfix_str(f\"{self.best_val_loss:.4f}\")\n",
        "        self.main_pbar.refresh()\n",
        "    \n",
        "    def close(self):\n",
        "        \"\"\"Close all progress bars\"\"\"\n",
        "        if self.epoch_pbar:\n",
        "            self.epoch_pbar.close()\n",
        "            self.epoch_pbar = None\n",
        "        if self.main_pbar:\n",
        "            self.main_pbar.close()\n",
        "            self.main_pbar = None\n",
        "    \n",
        "    def plot_progress(self):\n",
        "        \"\"\"Plot training progress\"\"\"\n",
        "        if not self.metrics['train_loss']:\n",
        "            return\n",
        "            \n",
        "        fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "        fig.suptitle(f'Training Progress - Epoch {self.current_epoch}', fontsize=16)\n",
        "        \n",
        "        # Loss curves\n",
        "        if self.metrics['train_loss'] and self.metrics['val_loss']:\n",
        "            epochs = range(1, len(self.metrics['train_loss']) + 1)\n",
        "            axes[0, 0].plot(epochs, self.metrics['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
        "            axes[0, 0].plot(epochs, self.metrics['val_loss'], 'r-', label='Val Loss', linewidth=2)\n",
        "            axes[0, 0].set_title('Training & Validation Loss')\n",
        "            axes[0, 0].set_xlabel('Epoch')\n",
        "            axes[0, 0].set_ylabel('Loss')\n",
        "            axes[0, 0].legend()\n",
        "            axes[0, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # KL and Reconstruction Loss\n",
        "        if self.metrics['kl_loss'] and self.metrics['recon_loss']:\n",
        "            epochs = range(1, len(self.metrics['kl_loss']) + 1)\n",
        "            axes[0, 1].plot(epochs, self.metrics['kl_loss'], 'g-', label='KL Loss', linewidth=2)\n",
        "            axes[0, 1].plot(epochs, self.metrics['recon_loss'], 'orange', label='Recon Loss', linewidth=2)\n",
        "            axes[0, 1].set_title('KL & Reconstruction Loss')\n",
        "            axes[0, 1].set_xlabel('Epoch')\n",
        "            axes[0, 1].set_ylabel('Loss')\n",
        "            axes[0, 1].legend()\n",
        "            axes[0, 1].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Beta annealing\n",
        "        if self.metrics['beta']:\n",
        "            epochs = range(1, len(self.metrics['beta']) + 1)\n",
        "            axes[1, 0].plot(epochs, self.metrics['beta'], 'purple', label='Beta', linewidth=2)\n",
        "            axes[1, 0].set_title('Beta Annealing')\n",
        "            axes[1, 0].set_xlabel('Epoch')\n",
        "            axes[1, 0].set_ylabel('Beta Value')\n",
        "            axes[1, 0].legend()\n",
        "            axes[1, 0].grid(True, alpha=0.3)\n",
        "        \n",
        "        # Summary stats\n",
        "        axes[1, 1].axis('off')\n",
        "        elapsed = time.time() - self.start_time\n",
        "        hours, remainder = divmod(elapsed, 3600)\n",
        "        minutes, seconds = divmod(remainder, 60)\n",
        "        \n",
        "        stats_text = f\"\"\"Training Statistics:\n",
        "\n",
        "Current Epoch: {self.current_epoch}\n",
        "Total Epochs: {self.total_epochs or 'Unknown'}\n",
        "Best Val Loss: {self.best_val_loss:.4f}\n",
        "Training Time: {int(hours):02d}:{int(minutes):02d}:{int(seconds):02d}\n",
        "\n",
        "Latest Metrics:\n",
        "Train Loss: {self.current_train_loss:.4f if self.current_train_loss else 'N/A'}\n",
        "Val Loss: {self.current_val_loss:.4f if self.current_val_loss else 'N/A'}\n",
        "KL Loss: {self.current_kl_loss:.4f if self.current_kl_loss else 'N/A'}\n",
        "Recon Loss: {self.current_recon_loss:.4f if self.current_recon_loss else 'N/A'}\n",
        "Beta: {self.current_beta:.4f if self.current_beta else 'N/A'}\n",
        "        \"\"\"\n",
        "        axes[1, 1].text(0.1, 0.5, stats_text, fontsize=11, verticalalignment='center',\n",
        "                bbox=dict(boxstyle=\"round,pad=0.3\", facecolor=\"lightblue\", alpha=0.7))\n",
        "        \n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "print(\"‚úÖ Enhanced training monitor with real-time updates ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéÆ GPU Monitoring and Optimization Functions\n",
        "def check_gpu_status():\n",
        "    \"\"\"Check current GPU status and usage\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        print(\"‚ùå CUDA not available!\")\n",
        "        print(\"üí° Enable GPU: Runtime > Change runtime type > Hardware accelerator > GPU\")\n",
        "        return False\n",
        "    \n",
        "    print(\"üéÆ GPU Status:\")\n",
        "    print(f\"  Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"  CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"  PyTorch CUDA: {torch.backends.cudnn.version()}\")\n",
        "    \n",
        "    # Memory info\n",
        "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    allocated = torch.cuda.memory_allocated(0) / 1e9\n",
        "    cached = torch.cuda.memory_reserved(0) / 1e9\n",
        "    free = total_memory - allocated\n",
        "    \n",
        "    print(f\"  Total Memory: {total_memory:.1f} GB\")\n",
        "    print(f\"  Allocated: {allocated:.2f} GB ({allocated/total_memory*100:.1f}%)\")\n",
        "    print(f\"  Cached: {cached:.2f} GB\")\n",
        "    print(f\"  Free: {free:.2f} GB\")\n",
        "    \n",
        "    # Performance check\n",
        "    print(\"\\nüî• Performance Test:\")\n",
        "    start_time = time.time()\n",
        "    x = torch.randn(1000, 1000, device=device)\n",
        "    y = torch.mm(x, x)\n",
        "    torch.cuda.synchronize()\n",
        "    gpu_time = time.time() - start_time\n",
        "    print(f\"  GPU Matrix Multiply (1000x1000): {gpu_time:.3f}s\")\n",
        "    \n",
        "    if gpu_time > 0.1:\n",
        "        print(\"‚ö†Ô∏è GPU seems slow. Check if GPU is properly enabled.\")\n",
        "    else:\n",
        "        print(\"‚úÖ GPU performance looks good!\")\n",
        "    \n",
        "    return True\n",
        "\n",
        "def optimize_for_colab():\n",
        "    \"\"\"Apply Colab-specific optimizations\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        return\n",
        "    \n",
        "    print(\"üöÄ Applying Colab GPU optimizations...\")\n",
        "    \n",
        "    # Clear cache\n",
        "    torch.cuda.empty_cache()\n",
        "    \n",
        "    # Set optimal settings\n",
        "    torch.backends.cudnn.benchmark = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    \n",
        "    # Memory management\n",
        "    torch.cuda.set_per_process_memory_fraction(0.9)\n",
        "    \n",
        "    # Check if we have enough memory for large batches\n",
        "    total_memory = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    if total_memory >= 15:\n",
        "        recommended_batch = 32\n",
        "    elif total_memory >= 8:\n",
        "        recommended_batch = 16\n",
        "    else:\n",
        "        recommended_batch = 8\n",
        "    \n",
        "    print(f\"‚úÖ Optimizations applied!\")\n",
        "    print(f\"üí° Recommended batch size: {recommended_batch}\")\n",
        "    \n",
        "    return recommended_batch\n",
        "\n",
        "def monitor_gpu_during_training():\n",
        "    \"\"\"Monitor GPU usage during training\"\"\"\n",
        "    if not torch.cuda.is_available():\n",
        "        return\n",
        "    \n",
        "    allocated = torch.cuda.memory_allocated(0) / 1e9\n",
        "    cached = torch.cuda.memory_reserved(0) / 1e9\n",
        "    total = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "    \n",
        "    return {\n",
        "        'allocated_gb': allocated,\n",
        "        'cached_gb': cached,\n",
        "        'total_gb': total,\n",
        "        'utilization_pct': (allocated / total) * 100\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ GPU monitoring functions ready!\")\n",
        "print(\"üìã Available functions:\")\n",
        "print(\"  - check_gpu_status(): Check GPU availability and performance\")\n",
        "print(\"  - optimize_for_colab(): Apply Colab-specific optimizations\")\n",
        "print(\"  - monitor_gpu_during_training(): Monitor GPU usage\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîÑ Complete Data Preprocessing Function\n",
        "def run_preprocessing():\n",
        "    \"\"\"Complete data preprocessing from Excel file to processed pickle files\"\"\"\n",
        "    \n",
        "    print(\"üîÑ Starting complete data preprocessing pipeline...\")\n",
        "    \n",
        "    # Check if preprocessed data already exists\n",
        "    processed_data_paths = [\n",
        "        \"data/processed/abr_processed_data.pkl\",\n",
        "        \"data/processed/abr_data_preprocessed.pkl\",\n",
        "        \"data/abr_processed_data.pkl\"\n",
        "    ]\n",
        "    \n",
        "    for path in processed_data_paths:\n",
        "        if os.path.exists(path):\n",
        "            print(f\"‚úÖ Preprocessed data found at: {path}\")\n",
        "            return True\n",
        "    \n",
        "    print(\"üìä No preprocessed data found. Starting from Excel file...\")\n",
        "    \n",
        "    # Look for Excel file in multiple locations\n",
        "    excel_paths = [\n",
        "        # Google Drive locations\n",
        "        f\"{DRIVE_PROJECT_PATH}/data/abr_data_preprocessed.xlsx\" if DRIVE_PROJECT_PATH else None,\n",
        "        f\"{DRIVE_PROJECT_PATH}/abr_data_preprocessed.xlsx\" if DRIVE_PROJECT_PATH else None,\n",
        "        \"/content/drive/MyDrive/abr_data_preprocessed.xlsx\",\n",
        "        \"/content/drive/MyDrive/data/abr_data_preprocessed.xlsx\",\n",
        "        # Local locations\n",
        "        \"data/abr_data_preprocessed.xlsx\",\n",
        "        \"data/raw/abr_data.xlsx\",\n",
        "        \"abr_data_preprocessed.xlsx\"\n",
        "    ]\n",
        "    \n",
        "    excel_file = None\n",
        "    for path in excel_paths:\n",
        "        if path and os.path.exists(path):\n",
        "            excel_file = path\n",
        "            print(f\"üìä Found Excel file at: {excel_file}\")\n",
        "            break\n",
        "    \n",
        "    if not excel_file:\n",
        "        print(\"‚ùå Excel file not found!\")\n",
        "        print(\"üîç Searched locations:\")\n",
        "        for path in excel_paths:\n",
        "            if path:\n",
        "                print(f\"  - {path}\")\n",
        "        print(\"\\nüí° Please upload your Excel file to one of these locations:\")\n",
        "        print(\"  - /content/drive/MyDrive/abr_data_preprocessed.xlsx\")\n",
        "        print(\"  - /content/drive/MyDrive/data/abr_data_preprocessed.xlsx\")\n",
        "        return False\n",
        "    \n",
        "    try:\n",
        "        # Create necessary directories\n",
        "        os.makedirs(\"data/processed\", exist_ok=True)\n",
        "        os.makedirs(\"data/raw\", exist_ok=True)\n",
        "        \n",
        "        print(\"üìñ Loading Excel file...\")\n",
        "        # Load the Excel file\n",
        "        df = pd.read_excel(excel_file)\n",
        "        print(f\"‚úÖ Loaded Excel file with shape: {df.shape}\")\n",
        "        print(f\"üìã Columns: {list(df.columns)}\")\n",
        "        \n",
        "        # Copy Excel file to local data directory if not already there\n",
        "        local_excel_path = \"data/abr_data_preprocessed.xlsx\"\n",
        "        if not os.path.exists(local_excel_path):\n",
        "            import shutil\n",
        "            shutil.copy2(excel_file, local_excel_path)\n",
        "            print(f\"üìÅ Copied Excel file to: {local_excel_path}\")\n",
        "        \n",
        "        # Try to use existing preprocessing script first\n",
        "        preprocess_scripts = [\"preprocess.py\", \"process_data.py\", \"src/preprocess.py\"]\n",
        "        script_found = None\n",
        "        \n",
        "        for script in preprocess_scripts:\n",
        "            if os.path.exists(script):\n",
        "                script_found = script\n",
        "                break\n",
        "        \n",
        "        if script_found:\n",
        "            print(f\"üîÑ Using existing preprocessing script: {script_found}\")\n",
        "            cmd = [sys.executable, script_found]\n",
        "            \n",
        "            result = subprocess.run(cmd, capture_output=True, text=True, timeout=600)\n",
        "            \n",
        "            if result.returncode == 0:\n",
        "                print(\"‚úÖ Preprocessing script completed successfully!\")\n",
        "                \n",
        "                # Check if output was created\n",
        "                for path in processed_data_paths:\n",
        "                    if os.path.exists(path):\n",
        "                        print(f\"‚úÖ Preprocessed data created at: {path}\")\n",
        "                        return True\n",
        "                        \n",
        "                print(\"‚ö†Ô∏è Script completed but no output found. Falling back to built-in preprocessing...\")\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Preprocessing script failed. Using built-in preprocessing...\")\n",
        "                if result.stderr:\n",
        "                    print(f\"Script error: {result.stderr}\")\n",
        "        \n",
        "        # Built-in preprocessing pipeline\n",
        "        print(\"üîÑ Running built-in preprocessing pipeline...\")\n",
        "        \n",
        "        # Basic preprocessing steps\n",
        "        print(\"üßπ Cleaning data...\")\n",
        "        \n",
        "        # Remove any completely empty rows/columns\n",
        "        df = df.dropna(how='all').dropna(axis=1, how='all')\n",
        "        \n",
        "        # Basic data validation\n",
        "        print(f\"üìä Data shape after cleaning: {df.shape}\")\n",
        "        \n",
        "        # Look for waveform data columns (typically numeric columns)\n",
        "        numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
        "        print(f\"üìà Found {len(numeric_cols)} numeric columns (potential waveform data)\")\n",
        "        \n",
        "        # Look for clinical data columns (typically contain keywords)\n",
        "        clinical_keywords = ['latency', 'amplitude', 'threshold', 'wave', 'peak']\n",
        "        clinical_cols = []\n",
        "        for col in df.columns:\n",
        "            if any(keyword.lower() in col.lower() for keyword in clinical_keywords):\n",
        "                clinical_cols.append(col)\n",
        "        \n",
        "        print(f\"üè• Found {len(clinical_cols)} potential clinical columns: {clinical_cols}\")\n",
        "        \n",
        "        # Create a basic processed dataset structure\n",
        "        processed_data = {\n",
        "            'raw_data': df,\n",
        "            'waveform_columns': numeric_cols,\n",
        "            'clinical_columns': clinical_cols,\n",
        "            'metadata': {\n",
        "                'original_shape': df.shape,\n",
        "                'processing_date': datetime.now().isoformat(),\n",
        "                'source_file': excel_file\n",
        "            }\n",
        "        }\n",
        "        \n",
        "        # Save processed data\n",
        "        output_path = \"data/processed/abr_processed_data.pkl\"\n",
        "        \n",
        "        print(f\"üíæ Saving processed data to: {output_path}\")\n",
        "        import pickle\n",
        "        with open(output_path, 'wb') as f:\n",
        "            pickle.dump(processed_data, f)\n",
        "        \n",
        "        print(\"‚úÖ Built-in preprocessing completed successfully!\")\n",
        "        print(f\"üìä Processed data saved with {len(df)} samples\")\n",
        "        print(f\"üìà Waveform columns: {len(numeric_cols)}\")\n",
        "        print(f\"üè• Clinical columns: {len(clinical_cols)}\")\n",
        "        \n",
        "        return True\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Preprocessing failed with error: {e}\")\n",
        "        import traceback\n",
        "        print(\"üîç Full error traceback:\")\n",
        "        traceback.print_exc()\n",
        "        return False\n",
        "\n",
        "def check_data_status():\n",
        "    \"\"\"Check the current status of data files\"\"\"\n",
        "    print(\"üìä Data Status Check:\")\n",
        "    print(\"=\" * 50)\n",
        "    \n",
        "    # Check for Excel files\n",
        "    excel_paths = [\n",
        "        f\"{DRIVE_PROJECT_PATH}/data/abr_data_preprocessed.xlsx\" if DRIVE_PROJECT_PATH else None,\n",
        "        f\"{DRIVE_PROJECT_PATH}/abr_data_preprocessed.xlsx\" if DRIVE_PROJECT_PATH else None,\n",
        "        \"/content/drive/MyDrive/abr_data_preprocessed.xlsx\",\n",
        "        \"data/abr_data_preprocessed.xlsx\",\n",
        "        \"abr_data_preprocessed.xlsx\"\n",
        "    ]\n",
        "    \n",
        "    print(\"üìÅ Excel Files:\")\n",
        "    excel_found = False\n",
        "    for path in excel_paths:\n",
        "        if path and os.path.exists(path):\n",
        "            size = os.path.getsize(path) / (1024*1024)  # MB\n",
        "            print(f\"  ‚úÖ {path} ({size:.1f} MB)\")\n",
        "            excel_found = True\n",
        "        elif path:\n",
        "            print(f\"  ‚ùå {path}\")\n",
        "    \n",
        "    if not excel_found:\n",
        "        print(\"  ‚ö†Ô∏è No Excel files found!\")\n",
        "    \n",
        "    # Check for processed files\n",
        "    processed_paths = [\n",
        "        \"data/processed/abr_processed_data.pkl\",\n",
        "        \"data/processed/abr_data_preprocessed.pkl\",\n",
        "        \"data/abr_processed_data.pkl\"\n",
        "    ]\n",
        "    \n",
        "    print(\"\\nüîÑ Processed Files:\")\n",
        "    processed_found = False\n",
        "    for path in processed_paths:\n",
        "        if os.path.exists(path):\n",
        "            size = os.path.getsize(path) / (1024*1024)  # MB\n",
        "            print(f\"  ‚úÖ {path} ({size:.1f} MB)\")\n",
        "            processed_found = True\n",
        "        else:\n",
        "            print(f\"  ‚ùå {path}\")\n",
        "    \n",
        "    if not processed_found:\n",
        "        print(\"  ‚ö†Ô∏è No processed files found!\")\n",
        "    \n",
        "    # Check preprocessing scripts\n",
        "    scripts = [\"preprocess.py\", \"process_data.py\", \"src/preprocess.py\"]\n",
        "    print(\"\\nüîß Preprocessing Scripts:\")\n",
        "    for script in scripts:\n",
        "        if os.path.exists(script):\n",
        "            print(f\"  ‚úÖ {script}\")\n",
        "        else:\n",
        "            print(f\"  ‚ùå {script}\")\n",
        "    \n",
        "    return excel_found, processed_found\n",
        "\n",
        "print(\"‚úÖ Complete preprocessing pipeline ready!\")\n",
        "print(\"üìã Available functions:\")\n",
        "print(\"  - run_preprocessing(): Complete preprocessing from Excel to pickle\")\n",
        "print(\"  - check_data_status(): Check current data file status\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéØ Training Function using existing train.py\n",
        "def run_training(model_type='original', epochs=50, batch_size=16, experiment_name=None):\n",
        "    \"\"\"Run training using the existing train.py script\"\"\"\n",
        "    import sys\n",
        "    import subprocess\n",
        "    import os\n",
        "    from datetime import datetime\n",
        "    \n",
        "    # Check if preprocessing is needed\n",
        "    processed_data_paths = [\n",
        "        \"data/processed/abr_processed_data.pkl\",\n",
        "        \"data/processed/abr_data_preprocessed.pkl\", \n",
        "        \"data/abr_processed_data.pkl\"\n",
        "    ]\n",
        "    \n",
        "    data_exists = any(os.path.exists(path) for path in processed_data_paths)\n",
        "    \n",
        "    if not data_exists:\n",
        "        print(\"üîÑ Preprocessed data not found. Running preprocessing first...\")\n",
        "        if not run_preprocessing():\n",
        "            print(\"‚ùå Preprocessing failed. Cannot proceed with training.\")\n",
        "            return None\n",
        "        print(\"‚úÖ Preprocessing completed. Starting training...\")\n",
        "    \n",
        "    if experiment_name is None:\n",
        "        experiment_name = f\"{model_type}_cvae_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "    \n",
        "    output_dir = f\"outputs_{experiment_name}\"\n",
        "    \n",
        "    # Create optimized config for GPU training\n",
        "    # Adjust batch size based on GPU availability and memory\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        if gpu_memory_gb >= 15:  # High-end GPU\n",
        "            optimal_batch_size = max(batch_size, 32)\n",
        "        elif gpu_memory_gb >= 8:  # Mid-range GPU\n",
        "            optimal_batch_size = max(batch_size, 16)\n",
        "        else:  # Lower-end GPU\n",
        "            optimal_batch_size = min(batch_size, 8)\n",
        "    else:\n",
        "        optimal_batch_size = min(batch_size, 4)  # CPU fallback\n",
        "    \n",
        "    # Optimized configuration for best advanced CVAE results\n",
        "    config = {\n",
        "        'data': {\n",
        "            'sequence_length': 256,  # Increased for better temporal modeling\n",
        "            'train_split': 0.75,     # More training data\n",
        "            'val_split': 0.15, \n",
        "            'test_split': 0.10,\n",
        "            'num_workers': 6 if torch.cuda.is_available() else 2,\n",
        "            'pin_memory': torch.cuda.is_available(),\n",
        "            'persistent_workers': torch.cuda.is_available(),\n",
        "            'prefetch_factor': 4,    # Faster data loading\n",
        "            'drop_last': True,       # Consistent batch sizes\n",
        "            # Data augmentation for better generalization\n",
        "            'augmentation': {\n",
        "                'noise_std': 0.01,   # Small noise injection\n",
        "                'time_shift': 0.05,  # Temporal shifts\n",
        "                'amplitude_scale': [0.95, 1.05]  # Amplitude variations\n",
        "            },\n",
        "            # Advanced preprocessing\n",
        "            'normalization': 'robust',  # Better for outliers\n",
        "            'feature_scaling': 'standard'\n",
        "        },\n",
        "        'model': {\n",
        "            'type': model_type,\n",
        "            'static_dim': 4,\n",
        "            \n",
        "            # Optimized architecture for advanced model\n",
        "            'latent_dim': 256 if model_type == 'advanced' else 128,  # Larger latent space\n",
        "            'hidden_dim': 512 if model_type == 'advanced' else 256,  # Deeper networks\n",
        "            'num_layers': 4 if model_type == 'advanced' else 3,      # More layers\n",
        "            \n",
        "            # Advanced model specific (hierarchical latents)\n",
        "            'hierarchical_latents': {\n",
        "                'global_dim': 128,    # Global features\n",
        "                'local_dim': 128,     # Local temporal features\n",
        "                'num_levels': 3       # Hierarchy levels\n",
        "            } if model_type == 'advanced' else None,\n",
        "            \n",
        "            # Regularization\n",
        "            'dropout': 0.15,          # Prevent overfitting\n",
        "            'layer_norm': True,       # Stable training\n",
        "            'spectral_norm': False,   # Can add if needed\n",
        "            \n",
        "            # Activation functions\n",
        "            'activation': 'gelu',     # Better than ReLU for transformers\n",
        "            'final_activation': 'tanh',\n",
        "            \n",
        "            # VAE specific\n",
        "            'beta_schedule': 'cyclical',  # Better than fixed beta\n",
        "            'beta_min': 0.1,\n",
        "            'beta_max': 4.0,\n",
        "            'beta_cycles': 4,         # Number of cycles during training\n",
        "            'kl_tolerance': 0.5,      # Free bits for KL\n",
        "            \n",
        "            # Advanced techniques\n",
        "            'mixed_precision': torch.cuda.is_available(),\n",
        "            'compile_model': torch.cuda.is_available(),\n",
        "            'gradient_checkpointing': True,  # Memory efficient\n",
        "        },\n",
        "        'training': {\n",
        "            'epochs': epochs,\n",
        "            'batch_size': optimal_batch_size,\n",
        "            'output_dir': output_dir,\n",
        "            'device': str(device),\n",
        "            \n",
        "            # Advanced training strategies\n",
        "            'gradient_accumulation_steps': 2,  # Effective larger batch size\n",
        "            'gradient_clip_norm': 1.0,         # Prevent exploding gradients\n",
        "            'mixed_precision': torch.cuda.is_available(),\n",
        "            'compile_model': torch.cuda.is_available(),\n",
        "            \n",
        "            # Optimized optimizer\n",
        "            'optimizer': {\n",
        "                'type': 'adamw',\n",
        "                'lr': 3e-4,              # Optimal for transformers\n",
        "                'weight_decay': 0.05,    # Strong regularization\n",
        "                'eps': 1e-8,\n",
        "                'betas': [0.9, 0.95],    # Optimized for VAEs\n",
        "                'amsgrad': True          # Better convergence\n",
        "            },\n",
        "            \n",
        "            # Advanced learning rate scheduling\n",
        "            'scheduler': {\n",
        "                'type': 'cosine_with_restarts',\n",
        "                'warmup_steps': max(200, epochs // 10),  # Proper warmup\n",
        "                'T_0': epochs // 4,      # First restart\n",
        "                'T_mult': 2,             # Restart multiplier\n",
        "                'eta_min': 1e-6,         # Minimum LR\n",
        "                'last_epoch': -1\n",
        "            },\n",
        "            \n",
        "            # Early stopping and model selection\n",
        "            'early_stopping': {\n",
        "                'patience': 15,          # More patience for complex model\n",
        "                'min_delta': 1e-4,       # Minimum improvement\n",
        "                'monitor': 'val_loss',\n",
        "                'mode': 'min',\n",
        "                'restore_best_weights': True\n",
        "            },\n",
        "            \n",
        "            # Model checkpointing\n",
        "            'checkpointing': {\n",
        "                'save_best': True,\n",
        "                'save_last': True,\n",
        "                'save_every_n_epochs': 10,\n",
        "                'monitor': 'val_loss'\n",
        "            },\n",
        "            \n",
        "            # Loss function weights (for advanced model)\n",
        "            'loss_weights': {\n",
        "                'reconstruction': 1.0,\n",
        "                'kl_divergence': 1.0,\n",
        "                'hierarchical_reg': 0.1 if model_type == 'advanced' else 0.0,\n",
        "                'consistency_reg': 0.05 if model_type == 'advanced' else 0.0\n",
        "            },\n",
        "            \n",
        "            # Validation and logging\n",
        "            'validation_freq': 1,       # Validate every epoch\n",
        "            'log_freq': 50,            # Log every 50 steps\n",
        "            'plot_freq': 5,            # Plot every 5 epochs\n",
        "            \n",
        "            # Advanced techniques\n",
        "            'label_smoothing': 0.1,     # Better generalization\n",
        "            'ema_decay': 0.999,         # Exponential moving average\n",
        "            'stochastic_weight_avg': True,  # Better final model\n",
        "        },\n",
        "        \n",
        "        # Evaluation configuration\n",
        "        'evaluation': {\n",
        "            'metrics': [\n",
        "                'reconstruction_error', 'kl_divergence', 'elbo',\n",
        "                'fid_score', 'inception_score', 'lpips',\n",
        "                'ssim', 'psnr', 'mse', 'mae',\n",
        "                'latent_traversal', 'interpolation_quality',\n",
        "                'disentanglement_score', 'mutual_info_gap'\n",
        "            ],\n",
        "            'num_samples': 1000,        # For evaluation\n",
        "            'batch_size': 64,\n",
        "            'save_reconstructions': True,\n",
        "            'save_generations': True,\n",
        "            'save_latent_space': True\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    print(f\"üéØ Optimized batch size: {optimal_batch_size} (requested: {batch_size})\")\n",
        "    print(f\"üîß GPU optimizations: {'Enabled' if torch.cuda.is_available() else 'Disabled'}\")\n",
        "    \n",
        "    # Save config\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    config_path = f\"{output_dir}/config.yaml\"\n",
        "    with open(config_path, 'w') as f:\n",
        "        yaml.dump(config, f)\n",
        "    \n",
        "    # Prepare training command (start with basic args)\n",
        "    cmd = [\n",
        "        sys.executable, \"train.py\",\n",
        "        \"--config\", config_path,\n",
        "        \"--output-dir\", output_dir,\n",
        "        \"--device\", str(device)\n",
        "    ]\n",
        "    \n",
        "    # Add optional arguments that the script might support\n",
        "    # We'll check what arguments train.py actually accepts\n",
        "    try:\n",
        "        # Check train.py help to see available arguments\n",
        "        help_result = subprocess.run([sys.executable, \"train.py\", \"--help\"], \n",
        "                                   capture_output=True, text=True, timeout=10)\n",
        "        available_args = help_result.stdout if help_result.returncode == 0 else \"\"\n",
        "        \n",
        "        # Only add arguments that are actually supported\n",
        "        if \"--model\" in available_args:\n",
        "            cmd.extend([\"--model\", model_type])\n",
        "        if \"--epochs\" in available_args:\n",
        "            cmd.extend([\"--epochs\", str(epochs)])\n",
        "        if \"--batch-size\" in available_args:\n",
        "            cmd.extend([\"--batch-size\", str(optimal_batch_size)])\n",
        "        elif \"--batch_size\" in available_args:\n",
        "            cmd.extend([\"--batch_size\", str(optimal_batch_size)])\n",
        "            \n",
        "        # Add GPU optimizations only if supported\n",
        "        if torch.cuda.is_available():\n",
        "            if \"--mixed-precision\" in available_args:\n",
        "                cmd.append(\"--mixed-precision\")\n",
        "            if \"--compile-model\" in available_args:\n",
        "                cmd.append(\"--compile-model\")\n",
        "            if \"--pin-memory\" in available_args:\n",
        "                cmd.append(\"--pin-memory\")\n",
        "            if \"--num-workers\" in available_args:\n",
        "                cmd.extend([\"--num-workers\", \"4\"])\n",
        "                \n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Could not check train.py arguments: {e}\")\n",
        "        # Fallback to basic arguments\n",
        "        cmd.extend([\"--epochs\", str(epochs)])\n",
        "    \n",
        "    print(f\"üöÄ Starting {model_type} CVAE training...\")\n",
        "    print(f\"üìã Command: {' '.join(cmd)}\")\n",
        "    \n",
        "    # Initialize monitor with total epochs\n",
        "    monitor = TrainingMonitor(total_epochs=epochs)\n",
        "    \n",
        "    try:\n",
        "        # First, let's test if train.py can be run at all\n",
        "        print(\"üîç Testing train.py script...\")\n",
        "        test_result = subprocess.run([sys.executable, \"train.py\", \"--help\"], \n",
        "                                   capture_output=True, text=True, timeout=30)\n",
        "        \n",
        "        if test_result.returncode != 0:\n",
        "            print(\"‚ùå train.py script has issues:\")\n",
        "            print(\"STDOUT:\", test_result.stdout)\n",
        "            print(\"STDERR:\", test_result.stderr)\n",
        "            return None\n",
        "        \n",
        "        print(\"‚úÖ train.py script is accessible\")\n",
        "        print(f\"üìã Final command: {' '.join(cmd)}\")\n",
        "        \n",
        "        # Run training with better error capture\n",
        "        process = subprocess.Popen(\n",
        "            cmd, stdout=subprocess.PIPE, stderr=subprocess.PIPE,\n",
        "            universal_newlines=True, bufsize=1\n",
        "        )\n",
        "        \n",
        "        line_count = 0\n",
        "        last_plot_epoch = 0\n",
        "        error_lines = []\n",
        "        \n",
        "        # Read both stdout and stderr with timeout\n",
        "        import select\n",
        "        import sys\n",
        "        import time\n",
        "        \n",
        "        start_time = time.time()\n",
        "        last_output_time = start_time\n",
        "        timeout_seconds = 300  # 5 minutes without output = timeout\n",
        "        \n",
        "        while True:\n",
        "            # Check if process is still running\n",
        "            if process.poll() is not None:\n",
        "                break\n",
        "                \n",
        "            # Check for timeout (no output for too long)\n",
        "            current_time = time.time()\n",
        "            if current_time - last_output_time > timeout_seconds:\n",
        "                print(f\"\\n‚è∞ No output for {timeout_seconds} seconds. Training might be stuck.\")\n",
        "                print(\"üîç Checking if process is still alive...\")\n",
        "                if process.poll() is None:\n",
        "                    print(\"‚ö†Ô∏è Process is still running but not producing output.\")\n",
        "                    print(\"üí° This might indicate:\")\n",
        "                    print(\"   - Very slow data loading\")\n",
        "                    print(\"   - GPU memory issues\")\n",
        "                    print(\"   - Model compilation taking too long\")\n",
        "                    print(\"   - Deadlock in training loop\")\n",
        "                    \n",
        "                    # Try to get some output\n",
        "                    try:\n",
        "                        remaining_stdout, remaining_stderr = process.communicate(timeout=10)\n",
        "                        if remaining_stdout:\n",
        "                            print(\"üìã Late stdout:\", remaining_stdout[-500:])\n",
        "                        if remaining_stderr:\n",
        "                            print(\"üìã Late stderr:\", remaining_stderr[-500:])\n",
        "                    except:\n",
        "                        print(\"‚ùå Could not get additional output\")\n",
        "                    \n",
        "                    # Kill the process\n",
        "                    print(\"üõë Terminating stuck process...\")\n",
        "                    process.terminate()\n",
        "                    try:\n",
        "                        process.wait(timeout=5)\n",
        "                    except:\n",
        "                        process.kill()\n",
        "                    break\n",
        "                else:\n",
        "                    break\n",
        "                \n",
        "            # Read available output\n",
        "            try:\n",
        "                stdout_line = process.stdout.readline()\n",
        "                if stdout_line:\n",
        "                    line = stdout_line.strip()\n",
        "                    if line:\n",
        "                        line_count += 1\n",
        "                        last_output_time = current_time  # Reset timeout\n",
        "                        \n",
        "                        # Parse metrics (this updates the tqdm bar)\n",
        "                        monitor.parse_log_line(line)\n",
        "                        \n",
        "                        # Print more lines initially for debugging\n",
        "                        if line_count < 100 or any(keyword in line for keyword in [\n",
        "                            'Starting', 'Loading', 'Epoch', 'Best model saved', 'Early stopping', 'completed', 'ERROR', 'WARNING', 'Traceback', 'Exception'\n",
        "                        ]):\n",
        "                            tqdm.write(f\"[{line_count:3d}] {line}\")\n",
        "                        \n",
        "                        # Collect error lines\n",
        "                        if any(keyword in line.lower() for keyword in ['error', 'exception', 'traceback', 'failed']):\n",
        "                            error_lines.append(line)\n",
        "                        \n",
        "                        # Show plot every 10 epochs\n",
        "                        if monitor.current_epoch > 0 and monitor.current_epoch != last_plot_epoch and monitor.current_epoch % 10 == 0:\n",
        "                            last_plot_epoch = monitor.current_epoch\n",
        "                            if monitor.metrics['train_loss']:\n",
        "                                print(f\"\\nüìä Training Progress Update (Epoch {monitor.current_epoch}):\")\n",
        "                                monitor.plot_progress()\n",
        "                else:\n",
        "                    # No output available, sleep briefly\n",
        "                    time.sleep(0.1)\n",
        "            except Exception as e:\n",
        "                print(f\"‚ö†Ô∏è Error reading output: {e}\")\n",
        "                break\n",
        "        \n",
        "        # Get any remaining output\n",
        "        remaining_stdout, remaining_stderr = process.communicate()\n",
        "        \n",
        "        if remaining_stdout:\n",
        "            for line in remaining_stdout.split('\\n'):\n",
        "                if line.strip():\n",
        "                    tqdm.write(line.strip())\n",
        "                    if any(keyword in line.lower() for keyword in ['error', 'exception', 'traceback']):\n",
        "                        error_lines.append(line.strip())\n",
        "        \n",
        "        if remaining_stderr:\n",
        "            print(\"\\nüîç STDERR Output:\")\n",
        "            for line in remaining_stderr.split('\\n'):\n",
        "                if line.strip():\n",
        "                    tqdm.write(f\"STDERR: {line.strip()}\")\n",
        "                    error_lines.append(f\"STDERR: {line.strip()}\")\n",
        "        \n",
        "        # Final results\n",
        "        return_code = process.returncode\n",
        "        \n",
        "        # Close progress bar\n",
        "        monitor.close()\n",
        "        \n",
        "        if return_code == 0:\n",
        "            print(\"\\n‚úÖ Training completed successfully!\")\n",
        "            \n",
        "            # Show final plot\n",
        "            if monitor.metrics['train_loss']:\n",
        "                print(\"üìä Final Training Results:\")\n",
        "                monitor.plot_progress()\n",
        "            \n",
        "            # Copy results to Drive if in Colab\n",
        "            if IN_COLAB and DRIVE_PROJECT_PATH:\n",
        "                drive_results_dir = f\"{DRIVE_PROJECT_PATH}/results/{experiment_name}\"\n",
        "                os.makedirs(f\"{DRIVE_PROJECT_PATH}/results\", exist_ok=True)\n",
        "                !cp -r \"{output_dir}\" \"{drive_results_dir}\"\n",
        "                print(f\"üíæ Results backed up to: {drive_results_dir}\")\n",
        "            \n",
        "            return output_dir\n",
        "        else:\n",
        "            print(f\"\\n‚ùå Training failed with return code: {return_code}\")\n",
        "            \n",
        "            if error_lines:\n",
        "                print(\"\\nüîç Error Summary:\")\n",
        "                for error in error_lines[-10:]:  # Show last 10 errors\n",
        "                    print(f\"  {error}\")\n",
        "            \n",
        "            # Check common issues\n",
        "            print(\"\\nüîß Troubleshooting:\")\n",
        "            print(\"1. Check if all required files exist:\")\n",
        "            print(f\"   - train.py: {'‚úÖ' if os.path.exists('train.py') else '‚ùå'}\")\n",
        "            print(f\"   - Config: {'‚úÖ' if os.path.exists(config_path) else '‚ùå'}\")\n",
        "            print(f\"   - Data: {'‚úÖ' if any(os.path.exists(p) for p in processed_data_paths) else '‚ùå'}\")\n",
        "            \n",
        "            print(\"2. Try running with simpler arguments:\")\n",
        "            simple_cmd = [sys.executable, \"train.py\", \"--config\", config_path]\n",
        "            print(f\"   {' '.join(simple_cmd)}\")\n",
        "            \n",
        "            return None\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Training error: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        # Make sure to close progress bar even on error\n",
        "        if 'monitor' in locals():\n",
        "            monitor.close()\n",
        "        return None\n",
        "    finally:\n",
        "        # Ensure progress bar is always closed\n",
        "        if 'monitor' in locals():\n",
        "            monitor.close()\n",
        "\n",
        "print(\"‚úÖ Training function ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üî¨ Evaluation Function using existing evaluate.py\n",
        "def run_evaluation(model_path=None, output_dir=None):\n",
        "    \"\"\"Run evaluation using the existing evaluate.py script\"\"\"\n",
        "    \n",
        "    # Find model if not specified\n",
        "    if model_path is None:\n",
        "        # Look for the most recent output directory\n",
        "        output_dirs = [d for d in os.listdir('.') if d.startswith('outputs_')]\n",
        "        if not output_dirs:\n",
        "            print(\"‚ùå No training outputs found. Please run training first.\")\n",
        "            return None\n",
        "        \n",
        "        latest_output_dir = max(output_dirs, key=lambda d: os.path.getmtime(d))\n",
        "        \n",
        "        # Look for best checkpoint\n",
        "        best_checkpoint = os.path.join(latest_output_dir, \"best_checkpoint.pth\")\n",
        "        if os.path.exists(best_checkpoint):\n",
        "            model_path = best_checkpoint\n",
        "        else:\n",
        "            # Look for any checkpoint\n",
        "            checkpoints = [f for f in os.listdir(latest_output_dir) if f.endswith('.pth')]\n",
        "            if checkpoints:\n",
        "                model_path = os.path.join(latest_output_dir, checkpoints[-1])\n",
        "            else:\n",
        "                print(f\"‚ùå No model checkpoints found in {latest_output_dir}\")\n",
        "                return None\n",
        "    \n",
        "    if output_dir is None:\n",
        "        output_dir = f\"evaluation_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "    \n",
        "    # Prepare evaluation command\n",
        "    cmd = [\n",
        "        sys.executable, \"evaluate.py\",\n",
        "        \"--model\", model_path,\n",
        "        \"--output-dir\", output_dir,\n",
        "        \"--comprehensive\"\n",
        "    ]\n",
        "    \n",
        "    print(f\"üî¨ Starting evaluation...\")\n",
        "    print(f\"üìã Model: {model_path}\")\n",
        "    print(f\"üìã Command: {' '.join(cmd)}\")\n",
        "    \n",
        "    try:\n",
        "        # Run evaluation\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=1800)  # 30 min timeout\n",
        "        \n",
        "        if result.stdout:\n",
        "            print(\"üìã Evaluation Output:\")\n",
        "            print(result.stdout)\n",
        "        \n",
        "        if result.stderr:\n",
        "            print(\"‚ö†Ô∏è Evaluation Warnings:\")\n",
        "            print(result.stderr)\n",
        "        \n",
        "        if result.returncode == 0:\n",
        "            print(\"‚úÖ Evaluation completed successfully!\")\n",
        "            \n",
        "            # Copy results to Drive if in Colab\n",
        "            if IN_COLAB and DRIVE_PROJECT_PATH:\n",
        "                drive_eval_dir = f\"{DRIVE_PROJECT_PATH}/evaluations/{output_dir}\"\n",
        "                os.makedirs(f\"{DRIVE_PROJECT_PATH}/evaluations\", exist_ok=True)\n",
        "                !cp -r \"{output_dir}\" \"{drive_eval_dir}\"\n",
        "                print(f\"üíæ Evaluation results backed up to: {drive_eval_dir}\")\n",
        "            \n",
        "            return output_dir\n",
        "        else:\n",
        "            print(f\"‚ùå Evaluation failed with return code: {result.returncode}\")\n",
        "            return None\n",
        "            \n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"‚ùå Evaluation timed out after 30 minutes\")\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Evaluation error: {e}\")\n",
        "        return None\n",
        "\n",
        "print(\"‚úÖ Evaluation function ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ Quick Start Functions\n",
        "def quick_train_original(epochs=50):\n",
        "    \"\"\"Quick training with original CVAE model\"\"\"\n",
        "    return run_training(model_type='original', epochs=epochs, experiment_name='original_quick')\n",
        "\n",
        "def quick_train_advanced(epochs=100):\n",
        "    \"\"\"Quick training with advanced CVAE model\"\"\"\n",
        "    return run_training(model_type='advanced', epochs=epochs, experiment_name='advanced_quick')\n",
        "\n",
        "def quick_evaluate():\n",
        "    \"\"\"Quick evaluation of the most recent model\"\"\"\n",
        "    return run_evaluation()\n",
        "\n",
        "def compare_models():\n",
        "    \"\"\"Train and compare both models\"\"\"\n",
        "    print(\"üî¨ Starting model comparison...\")\n",
        "    \n",
        "    # Train original model\n",
        "    print(\"\\nüöÄ Training Original CVAE (30 epochs)...\")\n",
        "    original_output = run_training('original', epochs=30, experiment_name='comparison_original')\n",
        "    \n",
        "    if original_output:\n",
        "        print(\"\\nüî¨ Evaluating Original CVAE...\")\n",
        "        run_evaluation(f\"{original_output}/best_checkpoint.pth\", \"eval_original\")\n",
        "    \n",
        "    # Train advanced model  \n",
        "    print(\"\\nüöÄ Training Advanced CVAE (50 epochs)...\")\n",
        "    advanced_output = run_training('advanced', epochs=50, experiment_name='comparison_advanced')\n",
        "    \n",
        "    if advanced_output:\n",
        "        print(\"\\nüî¨ Evaluating Advanced CVAE...\")\n",
        "        run_evaluation(f\"{advanced_output}/best_checkpoint.pth\", \"eval_advanced\")\n",
        "    \n",
        "    print(\"\\nüìä Model comparison complete!\")\n",
        "    if IN_COLAB:\n",
        "        print(f\"üìÅ Check your Google Drive at: {DRIVE_PROJECT_PATH}/results/\")\n",
        "    \n",
        "    return original_output, advanced_output\n",
        "\n",
        "def list_results():\n",
        "    \"\"\"List all training and evaluation results\"\"\"\n",
        "    print(\"üìÅ Local Results:\")\n",
        "    \n",
        "    # Training outputs\n",
        "    outputs = [d for d in os.listdir('.') if d.startswith('outputs_')]\n",
        "    if outputs:\n",
        "        print(\"üöÄ Training Results:\")\n",
        "        for output in sorted(outputs):\n",
        "            print(f\"  - {output}\")\n",
        "    \n",
        "    # Evaluation results\n",
        "    evals = [d for d in os.listdir('.') if d.startswith('evaluation_')]\n",
        "    if evals:\n",
        "        print(\"üî¨ Evaluation Results:\")\n",
        "        for eval_dir in sorted(evals):\n",
        "            print(f\"  - {eval_dir}\")\n",
        "    \n",
        "    # Drive results (if in Colab)\n",
        "    if IN_COLAB and DRIVE_PROJECT_PATH:\n",
        "        print(f\"\\nüìÅ Google Drive Results: {DRIVE_PROJECT_PATH}/\")\n",
        "        if os.path.exists(f\"{DRIVE_PROJECT_PATH}/results\"):\n",
        "            drive_results = os.listdir(f\"{DRIVE_PROJECT_PATH}/results\")\n",
        "            if drive_results:\n",
        "                print(\"üöÄ Drive Training Results:\")\n",
        "                for result in sorted(drive_results):\n",
        "                    print(f\"  - {result}\")\n",
        "        \n",
        "        if os.path.exists(f\"{DRIVE_PROJECT_PATH}/evaluations\"):\n",
        "            drive_evals = os.listdir(f\"{DRIVE_PROJECT_PATH}/evaluations\")\n",
        "            if drive_evals:\n",
        "                print(\"üî¨ Drive Evaluation Results:\")\n",
        "                for eval_dir in sorted(drive_evals):\n",
        "                    print(f\"  - {eval_dir}\")\n",
        "\n",
        "print(\"‚úÖ Quick start functions ready!\")\n",
        "print(\"\\nüöÄ Available functions:\")\n",
        "print(\"  - quick_train_original(epochs=50)\")\n",
        "print(\"  - quick_train_advanced(epochs=100)\")\n",
        "print(\"  - quick_evaluate()\")\n",
        "print(\"  - compare_models()\")\n",
        "print(\"  - list_results()\")\n",
        "print(\"\\nüí° Example usage:\")\n",
        "print(\"  quick_train_original()  # Train original model\")\n",
        "print(\"  quick_evaluate()        # Evaluate latest model\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéØ Ready to Use!\n",
        "\n",
        "**Your ABR CVAE project is now set up in Google Colab!**\n",
        "\n",
        "### üìã Quick Start:\n",
        "```python\n",
        "# Train original CVAE model (50 epochs)\n",
        "quick_train_original()\n",
        "\n",
        "# Train advanced CVAE model (100 epochs) \n",
        "quick_train_advanced()\n",
        "\n",
        "# Evaluate the most recent model\n",
        "quick_evaluate()\n",
        "\n",
        "# Compare both models\n",
        "compare_models()\n",
        "\n",
        "# List all results\n",
        "list_results()\n",
        "```\n",
        "\n",
        "### üìÅ File Structure:\n",
        "- **Local**: `/content/abr_project/` (working directory)\n",
        "- **Drive**: `/content/drive/MyDrive/abr_project/` (backup location)\n",
        "- **Results**: Automatically saved to both locations\n",
        "\n",
        "### üíæ Automatic Backup:\n",
        "All training outputs and evaluation results are automatically backed up to your Google Drive at:\n",
        "- Training: `/MyDrive/abr_project/results/`\n",
        "- Evaluations: `/MyDrive/abr_project/evaluations/`\n",
        "\n",
        "### üöÄ Start Training:\n",
        "Run the cell below to start training immediately!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ START TRAINING - Run this cell to begin!\n",
        "\n",
        "# Choose one of these options:\n",
        "\n",
        "# Option 1: Train original CVAE model (recommended for first run)\n",
        "quick_train_original(epochs=30)\n",
        "\n",
        "# Option 2: Train advanced CVAE model (more complex, takes longer)\n",
        "# quick_train_advanced(epochs=50)\n",
        "\n",
        "# Option 3: Compare both models (takes longest but most comprehensive)\n",
        "# compare_models()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîÑ DATA STATUS & PREPROCESSING\n",
        "\n",
        "# First, check what data files are available\n",
        "print(\"üîç Checking current data status...\")\n",
        "check_data_status()\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üîÑ Starting preprocessing...\")\n",
        "\n",
        "# Run complete preprocessing from Excel file\n",
        "run_preprocessing()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üéÆ GPU STATUS CHECK - Run this to verify GPU is working\n",
        "\n",
        "print(\"üîç Checking GPU status and performance...\")\n",
        "gpu_available = check_gpu_status()\n",
        "\n",
        "if gpu_available:\n",
        "    print(\"\\nüöÄ Applying optimizations...\")\n",
        "    recommended_batch = optimize_for_colab()\n",
        "    \n",
        "    print(f\"\\nüí° Training Tips:\")\n",
        "    print(f\"  - Use batch size: {recommended_batch} for optimal performance\")\n",
        "    print(f\"  - Mixed precision training: Enabled\")\n",
        "    print(f\"  - Model compilation: Enabled\")\n",
        "    print(f\"  - Expected speedup: 2-4x faster than CPU\")\n",
        "else:\n",
        "    print(\"\\n‚ùå GPU not available!\")\n",
        "    print(\"üîß To enable GPU:\")\n",
        "    print(\"  1. Go to Runtime > Change runtime type\")\n",
        "    print(\"  2. Set Hardware accelerator to 'GPU'\")\n",
        "    print(\"  3. Click Save and restart the runtime\")\n",
        "    print(\"  4. Re-run all cells\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîç DEBUG TRAINING SCRIPT - Run this if training fails\n",
        "\n",
        "def debug_training_setup():\n",
        "    \"\"\"Debug the training setup to identify issues\"\"\"\n",
        "    import sys\n",
        "    import subprocess\n",
        "    import os\n",
        "    \n",
        "    print(\"üîç Debugging training setup...\")\n",
        "    \n",
        "    # Check if train.py exists and is runnable\n",
        "    print(\"\\n1. üìÑ Checking train.py:\")\n",
        "    if os.path.exists(\"train.py\"):\n",
        "        print(\"   ‚úÖ train.py exists\")\n",
        "        \n",
        "        # Try to get help\n",
        "        try:\n",
        "            result = subprocess.run([sys.executable, \"train.py\", \"--help\"], \n",
        "                                  capture_output=True, text=True, timeout=10)\n",
        "            if result.returncode == 0:\n",
        "                print(\"   ‚úÖ train.py is runnable\")\n",
        "                print(\"   üìã Available arguments:\")\n",
        "                for line in result.stdout.split('\\n'):\n",
        "                    if '--' in line:\n",
        "                        print(f\"     {line.strip()}\")\n",
        "            else:\n",
        "                print(\"   ‚ùå train.py has issues:\")\n",
        "                print(f\"     STDOUT: {result.stdout}\")\n",
        "                print(f\"     STDERR: {result.stderr}\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Error running train.py: {e}\")\n",
        "    else:\n",
        "        print(\"   ‚ùå train.py not found\")\n",
        "    \n",
        "    # Check data files\n",
        "    print(\"\\n2. üìä Checking data files:\")\n",
        "    data_paths = [\n",
        "        \"data/processed/abr_processed_data.pkl\",\n",
        "        \"data/processed/abr_data_preprocessed.pkl\",\n",
        "        \"data/abr_processed_data.pkl\"\n",
        "    ]\n",
        "    \n",
        "    data_found = False\n",
        "    for path in data_paths:\n",
        "        if os.path.exists(path):\n",
        "            size = os.path.getsize(path) / (1024*1024)\n",
        "            print(f\"   ‚úÖ {path} ({size:.1f} MB)\")\n",
        "            data_found = True\n",
        "        else:\n",
        "            print(f\"   ‚ùå {path}\")\n",
        "    \n",
        "    if not data_found:\n",
        "        print(\"   ‚ö†Ô∏è No processed data found! Run preprocessing first.\")\n",
        "    \n",
        "    # Check GPU\n",
        "    print(\"\\n3. üéÆ Checking GPU:\")\n",
        "    if torch.cuda.is_available():\n",
        "        print(f\"   ‚úÖ GPU available: {torch.cuda.get_device_name(0)}\")\n",
        "        print(f\"   üìä Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    else:\n",
        "        print(\"   ‚ùå GPU not available\")\n",
        "    \n",
        "    # Check dependencies\n",
        "    print(\"\\n4. üì¶ Checking key dependencies:\")\n",
        "    deps = ['torch', 'numpy', 'pandas', 'yaml', 'sklearn']\n",
        "    for dep in deps:\n",
        "        try:\n",
        "            __import__(dep)\n",
        "            print(f\"   ‚úÖ {dep}\")\n",
        "        except ImportError:\n",
        "            print(f\"   ‚ùå {dep} not found\")\n",
        "    \n",
        "    # Try a minimal training command\n",
        "    print(\"\\n5. üß™ Testing minimal training command:\")\n",
        "    if os.path.exists(\"train.py\") and data_found:\n",
        "        # Create a minimal config\n",
        "        minimal_config = {\n",
        "            'data': {'sequence_length': 200},\n",
        "            'model': {'type': 'original'},\n",
        "            'training': {'epochs': 1, 'batch_size': 2}\n",
        "        }\n",
        "        \n",
        "        test_config_path = \"test_config.yaml\"\n",
        "        with open(test_config_path, 'w') as f:\n",
        "            yaml.dump(minimal_config, f)\n",
        "        \n",
        "        test_cmd = [sys.executable, \"train.py\", \"--config\", test_config_path]\n",
        "        print(f\"   üîß Command: {' '.join(test_cmd)}\")\n",
        "        \n",
        "        try:\n",
        "            result = subprocess.run(test_cmd, capture_output=True, text=True, timeout=60)\n",
        "            if result.returncode == 0:\n",
        "                print(\"   ‚úÖ Minimal training works!\")\n",
        "            else:\n",
        "                print(\"   ‚ùå Minimal training failed:\")\n",
        "                print(f\"     Return code: {result.returncode}\")\n",
        "                if result.stdout:\n",
        "                    print(\"     STDOUT:\", result.stdout[-500:])  # Last 500 chars\n",
        "                if result.stderr:\n",
        "                    print(\"     STDERR:\", result.stderr[-500:])  # Last 500 chars\n",
        "        except subprocess.TimeoutExpired:\n",
        "            print(\"   ‚è∞ Test timed out (might be working but slow)\")\n",
        "        except Exception as e:\n",
        "            print(f\"   ‚ùå Test error: {e}\")\n",
        "        finally:\n",
        "            # Clean up\n",
        "            if os.path.exists(test_config_path):\n",
        "                os.remove(test_config_path)\n",
        "    \n",
        "    print(\"\\n‚úÖ Debug complete!\")\n",
        "\n",
        "# Run the debug\n",
        "debug_training_setup()\n",
        "\n",
        "def test_training_script():\n",
        "    \"\"\"Test if train.py works with minimal arguments\"\"\"\n",
        "    import sys\n",
        "    import subprocess\n",
        "    import os\n",
        "    \n",
        "    print(\"üß™ Testing train.py with minimal arguments...\")\n",
        "    \n",
        "    # Create a very simple config\n",
        "    simple_config = {\n",
        "        'data': {'sequence_length': 200},\n",
        "        'model': {'type': 'original', 'latent_dim': 32, 'hidden_dim': 64},\n",
        "        'training': {'epochs': 1, 'batch_size': 2, 'output_dir': 'test_output'}\n",
        "    }\n",
        "    \n",
        "    test_config_path = \"minimal_test_config.yaml\"\n",
        "    with open(test_config_path, 'w') as f:\n",
        "        yaml.dump(simple_config, f)\n",
        "    \n",
        "    # Test command\n",
        "    cmd = [sys.executable, \"train.py\", \"--config\", test_config_path]\n",
        "    print(f\"üîß Test command: {' '.join(cmd)}\")\n",
        "    \n",
        "    try:\n",
        "        # Run with timeout\n",
        "        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)\n",
        "        \n",
        "        print(f\"üìã Return code: {result.returncode}\")\n",
        "        \n",
        "        if result.stdout:\n",
        "            print(\"üìã STDOUT (last 1000 chars):\")\n",
        "            print(result.stdout[-1000:])\n",
        "        \n",
        "        if result.stderr:\n",
        "            print(\"üìã STDERR (last 1000 chars):\")\n",
        "            print(result.stderr[-1000:])\n",
        "            \n",
        "        if result.returncode == 0:\n",
        "            print(\"‚úÖ Basic training script works!\")\n",
        "        else:\n",
        "            print(\"‚ùå Training script has issues\")\n",
        "            \n",
        "    except subprocess.TimeoutExpired:\n",
        "        print(\"‚è∞ Test timed out after 2 minutes\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Test error: {e}\")\n",
        "    finally:\n",
        "        # Clean up\n",
        "        if os.path.exists(test_config_path):\n",
        "            os.remove(test_config_path)\n",
        "        if os.path.exists(\"test_output\"):\n",
        "            import shutil\n",
        "            shutil.rmtree(\"test_output\", ignore_errors=True)\n",
        "\n",
        "print(\"\\nüß™ Run test_training_script() to test the basic training functionality\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ OPTIMIZED QUICK START FUNCTIONS - Best configurations for advanced CVAE\n",
        "\n",
        "def quick_train_original_optimized(epochs=50):\n",
        "    \"\"\"Train original CVAE with optimized settings\"\"\"\n",
        "    return run_training('original', epochs=epochs, batch_size=16, experiment_name='original_optimized')\n",
        "\n",
        "def quick_train_advanced_best(epochs=100):\n",
        "    \"\"\"Train advanced CVAE with best possible settings for optimal results\"\"\"\n",
        "    print(\"üéØ Starting BEST advanced CVAE training with optimal hyperparameters:\")\n",
        "    print(\"   ‚ú® Hierarchical latent spaces (256D)\")\n",
        "    print(\"   üîÑ Cyclical beta annealing\")\n",
        "    print(\"   üìà Cosine learning rate with restarts\")\n",
        "    print(\"   üéÆ GPU optimizations enabled\")\n",
        "    print(\"   üõ°Ô∏è Advanced regularization\")\n",
        "    print(\"   üìä Comprehensive evaluation metrics\")\n",
        "    \n",
        "    # Use optimal batch size based on GPU memory\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        if gpu_memory_gb >= 15:\n",
        "            optimal_batch = 32\n",
        "        elif gpu_memory_gb >= 10:\n",
        "            optimal_batch = 24\n",
        "        else:\n",
        "            optimal_batch = 16\n",
        "    else:\n",
        "        optimal_batch = 8\n",
        "    \n",
        "    print(f\"üéÆ Using optimal batch size: {optimal_batch}\")\n",
        "    return run_training('advanced', epochs=epochs, batch_size=optimal_batch, experiment_name='advanced_best')\n",
        "\n",
        "def quick_train_advanced_fast(epochs=50):\n",
        "    \"\"\"Train advanced CVAE with good settings (faster for testing)\"\"\"\n",
        "    return run_training('advanced', epochs=epochs, batch_size=16, experiment_name='advanced_fast')\n",
        "\n",
        "def train_advanced_production(epochs=200):\n",
        "    \"\"\"Production-quality training with all optimizations for publication-ready results\"\"\"\n",
        "    print(\"üèÜ PRODUCTION TRAINING - Publication-ready advanced CVAE\")\n",
        "    print(\"üéØ This configuration is optimized for:\")\n",
        "    print(\"   üìä Maximum reconstruction quality\")\n",
        "    print(\"   üß† Best latent space disentanglement\") \n",
        "    print(\"   üî¨ Comprehensive evaluation metrics\")\n",
        "    print(\"   üíæ Automatic checkpointing and backup\")\n",
        "    print(\"   ‚ö° GPU acceleration with mixed precision\")\n",
        "    print(\"   üõ°Ô∏è Advanced regularization techniques\")\n",
        "    print(\"   üìà Adaptive learning rate scheduling\")\n",
        "    print(\"   üîÑ Cyclical beta annealing for better KL balance\")\n",
        "    \n",
        "    # Use maximum optimal batch size\n",
        "    if torch.cuda.is_available():\n",
        "        gpu_memory_gb = torch.cuda.get_device_properties(0).total_memory / 1e9\n",
        "        if gpu_memory_gb >= 15:\n",
        "            optimal_batch = 32\n",
        "        elif gpu_memory_gb >= 10:\n",
        "            optimal_batch = 28\n",
        "        elif gpu_memory_gb >= 8:\n",
        "            optimal_batch = 20\n",
        "        else:\n",
        "            optimal_batch = 16\n",
        "    else:\n",
        "        optimal_batch = 8\n",
        "    \n",
        "    print(f\"üéÆ Production batch size: {optimal_batch}\")\n",
        "    print(f\"‚è±Ô∏è Estimated training time: {epochs * 2} minutes\")\n",
        "    \n",
        "    return run_training('advanced', epochs=epochs, batch_size=optimal_batch, experiment_name='advanced_production')\n",
        "\n",
        "def compare_models_optimized(epochs=75):\n",
        "    \"\"\"Compare both models with optimized settings\"\"\"\n",
        "    print(\"üîÑ Training Original CVAE with optimized settings...\")\n",
        "    original_results = quick_train_original_optimized(epochs)\n",
        "    \n",
        "    print(\"\\nüîÑ Training Advanced CVAE with optimized settings...\")\n",
        "    advanced_results = quick_train_advanced_best(epochs)\n",
        "    \n",
        "    return original_results, advanced_results\n",
        "\n",
        "print(\"‚úÖ OPTIMIZED training functions ready!\")\n",
        "print(\"\\nüöÄ Available optimized functions:\")\n",
        "print(\"  üü¢ quick_train_original_optimized(epochs=50) - Original CVAE with best settings\")\n",
        "print(\"  üî• quick_train_advanced_best(epochs=100) - Advanced CVAE optimized for best results\")\n",
        "print(\"  ‚ö° quick_train_advanced_fast(epochs=50) - Advanced CVAE for quick testing\")\n",
        "print(\"  üèÜ train_advanced_production(epochs=200) - Production-quality training\")\n",
        "print(\"  üìä compare_models_optimized(epochs=75) - Compare both with optimal settings\")\n",
        "\n",
        "print(\"\\nüéØ RECOMMENDED FOR BEST RESULTS:\")\n",
        "print(\"  train_advanced_production(epochs=200)\")\n",
        "print(\"\\n‚ö° RECOMMENDED FOR QUICK TESTING:\")\n",
        "print(\"  quick_train_advanced_fast(epochs=50)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üöÄ OPTIMIZED TRAINING EXECUTION - Choose your training strategy\n",
        "\n",
        "print(\"üéØ OPTIMIZED TRAINING OPTIONS:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Option 1: Production-quality training (BEST RESULTS)\n",
        "print(\"üèÜ Option 1: Production Training (RECOMMENDED)\")\n",
        "print(\"   - 200 epochs with all optimizations\")\n",
        "print(\"   - Publication-ready results\")\n",
        "print(\"   - Estimated time: ~6-7 hours\")\n",
        "print(\"   - Best reconstruction quality\")\n",
        "print(\"   - Optimal latent space disentanglement\")\n",
        "# train_advanced_production(epochs=200)\n",
        "\n",
        "print(\"\\nüî• Option 2: Best Training (GOOD BALANCE)\")\n",
        "print(\"   - 100 epochs with optimal settings\")\n",
        "print(\"   - High-quality results\")\n",
        "print(\"   - Estimated time: ~3-4 hours\")\n",
        "print(\"   - Excellent performance\")\n",
        "# quick_train_advanced_best(epochs=100)\n",
        "\n",
        "print(\"\\n‚ö° Option 3: Fast Training (QUICK TESTING)\")\n",
        "print(\"   - 50 epochs for rapid iteration\")\n",
        "print(\"   - Good results for testing\")\n",
        "print(\"   - Estimated time: ~1-2 hours\")\n",
        "print(\"   - Perfect for experimentation\")\n",
        "quick_train_advanced_fast(epochs=50)\n",
        "\n",
        "print(\"\\nüìä Option 4: Model Comparison\")\n",
        "print(\"   - Compare original vs advanced\")\n",
        "print(\"   - 75 epochs each\")\n",
        "print(\"   - Estimated time: ~4-5 hours\")\n",
        "# compare_models_optimized(epochs=75)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üí° TIPS:\")\n",
        "print(\"  - Uncomment the option you want to run\")\n",
        "print(\"  - Only run one option at a time\")\n",
        "print(\"  - Results are automatically saved to Google Drive\")\n",
        "print(\"  - GPU acceleration is automatically enabled\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîÑ RUN PREPROCESSING - Run this if you get data preprocessing errors\n",
        "\n",
        "# This will automatically run when needed, but you can also run it manually\n",
        "run_preprocessing()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üî¨ EVALUATE MODEL - Run this after training completes\n",
        "\n",
        "# Evaluate the most recent trained model\n",
        "quick_evaluate()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üî¨ EVALUATE MODEL - Run this after training completes\n",
        "\n",
        "# Evaluate the most recent trained model\n",
        "quick_evaluate()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
