#!/usr/bin/env python3
"""
Comprehensive Evaluation Metrics for Synthetic ABR Data Quality
==============================================================

This module provides various metrics to evaluate the quality of synthetic
ABR waveforms generated by the CVAE model, including both general ML metrics
and domain-specific ABR evaluation criteria.
"""

import torch
import numpy as np
import scipy.stats as stats
from scipy import signal
from scipy.fft import fft, fftfreq
from sklearn.metrics import mean_squared_error, mean_absolute_error
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.neighbors import NearestNeighbors
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Optional
import logging

logger = logging.getLogger(__name__)

class ABRSyntheticDataEvaluator:
    """Comprehensive evaluator for synthetic ABR data quality."""
    
    def __init__(self, sampling_rate: float = 1000.0):
        """
        Initialize evaluator.
        
        Args:
            sampling_rate: Sampling rate of ABR signals in Hz
        """
        self.sampling_rate = sampling_rate
        self.metrics_history = {}
    
    # ========================================
    # 1. RECONSTRUCTION QUALITY METRICS
    # ========================================
    
    def compute_reconstruction_metrics(self, 
                                     original: np.ndarray, 
                                     reconstructed: np.ndarray) -> Dict[str, float]:
        """
        Compute basic reconstruction quality metrics.
        
        Args:
            original: Original ABR waveforms [n_samples, sequence_length]
            reconstructed: Reconstructed waveforms [n_samples, sequence_length]
        
        Returns:
            Dictionary of reconstruction metrics
        """
        metrics = {}
        
        # Mean Squared Error
        metrics['mse'] = mean_squared_error(original.flatten(), reconstructed.flatten())
        metrics['rmse'] = np.sqrt(metrics['mse'])
        
        # Mean Absolute Error
        metrics['mae'] = mean_absolute_error(original.flatten(), reconstructed.flatten())
        
        # Peak Signal-to-Noise Ratio
        max_val = np.max(original)
        metrics['psnr'] = 20 * np.log10(max_val / np.sqrt(metrics['mse']))
        
        # Structural Similarity Index (simplified)
        metrics['ssim'] = self._compute_ssim(original, reconstructed)
        
        # Correlation coefficient
        correlations = [np.corrcoef(orig, recon)[0, 1] 
                       for orig, recon in zip(original, reconstructed)]
        metrics['mean_correlation'] = np.mean(correlations)
        metrics['std_correlation'] = np.std(correlations)
        
        return metrics
    
    def _compute_ssim(self, original: np.ndarray, reconstructed: np.ndarray) -> float:
        """Simplified SSIM computation for 1D signals."""
        mu1 = np.mean(original, axis=1)
        mu2 = np.mean(reconstructed, axis=1)
        
        sigma1_sq = np.var(original, axis=1)
        sigma2_sq = np.var(reconstructed, axis=1)
        sigma12 = np.mean((original - mu1[:, np.newaxis]) * 
                         (reconstructed - mu2[:, np.newaxis]), axis=1)
        
        C1, C2 = 0.01**2, 0.03**2
        ssim_values = ((2 * mu1 * mu2 + C1) * (2 * sigma12 + C2)) / \
                     ((mu1**2 + mu2**2 + C1) * (sigma1_sq + sigma2_sq + C2))
        
        return np.mean(ssim_values)
    
    # ========================================
    # 2. DISTRIBUTIONAL SIMILARITY METRICS
    # ========================================
    
    def compute_distributional_metrics(self, 
                                     real_data: np.ndarray, 
                                     synthetic_data: np.ndarray) -> Dict[str, float]:
        """
        Compute metrics comparing distributions of real vs synthetic data.
        
        Args:
            real_data: Real ABR waveforms [n_samples, sequence_length]
            synthetic_data: Synthetic ABR waveforms [n_samples, sequence_length]
        
        Returns:
            Dictionary of distributional metrics
        """
        metrics = {}
        
        # Wasserstein Distance (Earth Mover's Distance)
        real_flat = real_data.flatten()
        synthetic_flat = synthetic_data.flatten()
        metrics['wasserstein_distance'] = stats.wasserstein_distance(real_flat, synthetic_flat)
        
        # Kolmogorov-Smirnov Test
        ks_statistic, ks_p_value = stats.ks_2samp(real_flat, synthetic_flat)
        metrics['ks_statistic'] = ks_statistic
        metrics['ks_p_value'] = ks_p_value
        
        # Jensen-Shannon Divergence
        metrics['js_divergence'] = self._compute_js_divergence(real_flat, synthetic_flat)
        
        # Maximum Mean Discrepancy (MMD)
        metrics['mmd'] = self._compute_mmd(real_data, synthetic_data)
        
        # Statistical moments comparison
        real_moments = self._compute_moments(real_data)
        synthetic_moments = self._compute_moments(synthetic_data)
        
        metrics['mean_diff'] = np.abs(real_moments['mean'] - synthetic_moments['mean'])
        metrics['std_diff'] = np.abs(real_moments['std'] - synthetic_moments['std'])
        metrics['skew_diff'] = np.abs(real_moments['skew'] - synthetic_moments['skew'])
        metrics['kurtosis_diff'] = np.abs(real_moments['kurtosis'] - synthetic_moments['kurtosis'])
        
        return metrics
    
    def _compute_js_divergence(self, real_data: np.ndarray, synthetic_data: np.ndarray) -> float:
        """Compute Jensen-Shannon divergence between two distributions."""
        # Create histograms
        bins = np.linspace(min(real_data.min(), synthetic_data.min()),
                          max(real_data.max(), synthetic_data.max()), 50)
        
        p, _ = np.histogram(real_data, bins=bins, density=True)
        q, _ = np.histogram(synthetic_data, bins=bins, density=True)
        
        # Normalize
        p = p / np.sum(p)
        q = q / np.sum(q)
        
        # Avoid log(0)
        p = np.where(p == 0, 1e-10, p)
        q = np.where(q == 0, 1e-10, q)
        
        # Jensen-Shannon divergence
        m = 0.5 * (p + q)
        js = 0.5 * stats.entropy(p, m) + 0.5 * stats.entropy(q, m)
        
        return js
    
    def _compute_mmd(self, real_data: np.ndarray, synthetic_data: np.ndarray) -> float:
        """Compute Maximum Mean Discrepancy using RBF kernel."""
        def rbf_kernel(x, y, sigma=1.0):
            return np.exp(-np.linalg.norm(x - y)**2 / (2 * sigma**2))
        
        n_real = len(real_data)
        n_synthetic = len(synthetic_data)
        
        # Sample subset for efficiency
        if n_real > 1000:
            idx_real = np.random.choice(n_real, 1000, replace=False)
            real_subset = real_data[idx_real]
        else:
            real_subset = real_data
            
        if n_synthetic > 1000:
            idx_synthetic = np.random.choice(n_synthetic, 1000, replace=False)
            synthetic_subset = synthetic_data[idx_synthetic]
        else:
            synthetic_subset = synthetic_data
        
        # Compute MMD
        xx = np.mean([rbf_kernel(x1, x2) for x1 in real_subset for x2 in real_subset])
        yy = np.mean([rbf_kernel(y1, y2) for y1 in synthetic_subset for y2 in synthetic_subset])
        xy = np.mean([rbf_kernel(x, y) for x in real_subset for y in synthetic_subset])
        
        mmd = xx + yy - 2 * xy
        return mmd
    
    def _compute_moments(self, data: np.ndarray) -> Dict[str, float]:
        """Compute statistical moments of the data."""
        flat_data = data.flatten()
        return {
            'mean': np.mean(flat_data),
            'std': np.std(flat_data),
            'skew': stats.skew(flat_data),
            'kurtosis': stats.kurtosis(flat_data)
        }
    
    # ========================================
    # 3. FREQUENCY DOMAIN ANALYSIS
    # ========================================
    
    def compute_frequency_metrics(self, 
                                real_data: np.ndarray, 
                                synthetic_data: np.ndarray) -> Dict[str, float]:
        """
        Analyze frequency domain characteristics.
        
        Args:
            real_data: Real ABR waveforms [n_samples, sequence_length]
            synthetic_data: Synthetic ABR waveforms [n_samples, sequence_length]
        
        Returns:
            Dictionary of frequency domain metrics
        """
        metrics = {}
        
        # Compute power spectral densities
        real_psd = self._compute_average_psd(real_data)
        synthetic_psd = self._compute_average_psd(synthetic_data)
        
        # Frequency domain similarity
        metrics['psd_mse'] = mean_squared_error(real_psd, synthetic_psd)
        metrics['psd_correlation'] = np.corrcoef(real_psd, synthetic_psd)[0, 1]
        
        # Spectral centroid comparison
        real_centroid = self._compute_spectral_centroid(real_data)
        synthetic_centroid = self._compute_spectral_centroid(synthetic_data)
        
        metrics['spectral_centroid_diff'] = np.abs(np.mean(real_centroid) - 
                                                  np.mean(synthetic_centroid))
        
        # Bandwidth comparison
        real_bandwidth = self._compute_bandwidth(real_data)
        synthetic_bandwidth = self._compute_bandwidth(synthetic_data)
        
        metrics['bandwidth_diff'] = np.abs(np.mean(real_bandwidth) - 
                                          np.mean(synthetic_bandwidth))
        
        return metrics
    
    def _compute_average_psd(self, data: np.ndarray) -> np.ndarray:
        """Compute average power spectral density."""
        psds = []
        for waveform in data:
            freqs, psd = signal.periodogram(waveform, fs=self.sampling_rate)
            psds.append(psd)
        return np.mean(psds, axis=0)
    
    def _compute_spectral_centroid(self, data: np.ndarray) -> np.ndarray:
        """Compute spectral centroid for each waveform."""
        centroids = []
        for waveform in data:
            freqs, psd = signal.periodogram(waveform, fs=self.sampling_rate)
            centroid = np.sum(freqs * psd) / np.sum(psd)
            centroids.append(centroid)
        return np.array(centroids)
    
    def _compute_bandwidth(self, data: np.ndarray) -> np.ndarray:
        """Compute spectral bandwidth for each waveform."""
        bandwidths = []
        for waveform in data:
            freqs, psd = signal.periodogram(waveform, fs=self.sampling_rate)
            centroid = np.sum(freqs * psd) / np.sum(psd)
            bandwidth = np.sqrt(np.sum(((freqs - centroid) ** 2) * psd) / np.sum(psd))
            bandwidths.append(bandwidth)
        return np.array(bandwidths)
    
    # ========================================
    # 4. ABR-SPECIFIC CLINICAL METRICS
    # ========================================
    
    def compute_abr_clinical_metrics(self, 
                                   real_data: np.ndarray, 
                                   synthetic_data: np.ndarray,
                                   time_window: Tuple[float, float] = (0, 15)) -> Dict[str, float]:
        """
        Compute ABR-specific clinical metrics.
        
        Args:
            real_data: Real ABR waveforms [n_samples, sequence_length]
            synthetic_data: Synthetic ABR waveforms [n_samples, sequence_length]
            time_window: Time window in milliseconds for analysis
        
        Returns:
            Dictionary of ABR-specific metrics
        """
        metrics = {}
        
        # Peak detection and analysis
        real_peaks = self._detect_abr_peaks(real_data)
        synthetic_peaks = self._detect_abr_peaks(synthetic_data)
        
        # Wave I, III, V peak latency comparison
        for wave in ['I', 'III', 'V']:
            if wave in real_peaks and wave in synthetic_peaks:
                real_latencies = [p['latency'] for p in real_peaks[wave] if p is not None]
                synthetic_latencies = [p['latency'] for p in synthetic_peaks[wave] if p is not None]
                
                if real_latencies and synthetic_latencies:
                    metrics[f'wave_{wave}_latency_diff'] = np.abs(
                        np.mean(real_latencies) - np.mean(synthetic_latencies)
                    )
        
        # Amplitude preservation
        real_amplitudes = self._compute_peak_amplitudes(real_data)
        synthetic_amplitudes = self._compute_peak_amplitudes(synthetic_data)
        
        metrics['amplitude_correlation'] = np.corrcoef(
            real_amplitudes, synthetic_amplitudes
        )[0, 1] if len(real_amplitudes) == len(synthetic_amplitudes) else 0.0
        
        # Morphological similarity (template matching)
        metrics['morphological_similarity'] = self._compute_morphological_similarity(
            real_data, synthetic_data
        )
        
        return metrics
    
    def _detect_abr_peaks(self, data: np.ndarray) -> Dict[str, List]:
        """Detect ABR peaks (simplified implementation)."""
        peaks = {'I': [], 'III': [], 'V': []}
        
        for waveform in data:
            # Find peaks with prominence
            peak_indices, properties = signal.find_peaks(
                waveform, height=0.1, distance=10, prominence=0.05
            )
            
            # Classify peaks based on typical ABR timing
            # Wave I: ~1-2ms, Wave III: ~3-4ms, Wave V: ~5-6ms
            time_points = peak_indices / self.sampling_rate * 1000  # Convert to ms
            
            for i, (peak_idx, time_ms) in enumerate(zip(peak_indices, time_points)):
                peak_info = {
                    'latency': time_ms,
                    'amplitude': waveform[peak_idx],
                    'index': peak_idx
                }
                
                if 1.0 <= time_ms <= 2.5:
                    peaks['I'].append(peak_info)
                elif 2.5 <= time_ms <= 4.5:
                    peaks['III'].append(peak_info)
                elif 4.5 <= time_ms <= 7.0:
                    peaks['V'].append(peak_info)
        
        return peaks
    
    def _compute_peak_amplitudes(self, data: np.ndarray) -> np.ndarray:
        """Compute peak-to-peak amplitudes."""
        amplitudes = []
        for waveform in data:
            max_amp = np.max(waveform)
            min_amp = np.min(waveform)
            amplitudes.append(max_amp - min_amp)
        return np.array(amplitudes)
    
    def _compute_morphological_similarity(self, 
                                        real_data: np.ndarray, 
                                        synthetic_data: np.ndarray) -> float:
        """Compute morphological similarity using cross-correlation."""
        similarities = []
        
        # Compare each synthetic waveform with real template
        real_template = np.mean(real_data, axis=0)
        
        for synthetic_waveform in synthetic_data:
            correlation = np.corrcoef(real_template, synthetic_waveform)[0, 1]
            similarities.append(correlation)
        
        return np.mean(similarities)
    
    # ========================================
    # 5. DIVERSITY AND COVERAGE METRICS
    # ========================================
    
    def compute_diversity_metrics(self, 
                                synthetic_data: np.ndarray,
                                real_data: Optional[np.ndarray] = None) -> Dict[str, float]:
        """
        Compute diversity and coverage metrics for synthetic data.
        
        Args:
            synthetic_data: Synthetic ABR waveforms [n_samples, sequence_length]
            real_data: Optional real data for coverage comparison
        
        Returns:
            Dictionary of diversity metrics
        """
        metrics = {}
        
        # Intra-class diversity (within synthetic data)
        pairwise_distances = self._compute_pairwise_distances(synthetic_data)
        metrics['mean_pairwise_distance'] = np.mean(pairwise_distances)
        metrics['std_pairwise_distance'] = np.std(pairwise_distances)
        
        # Nearest neighbor distances
        nn_distances = self._compute_nearest_neighbor_distances(synthetic_data)
        metrics['mean_nn_distance'] = np.mean(nn_distances)
        metrics['min_nn_distance'] = np.min(nn_distances)
        
        # Mode collapse detection
        metrics['mode_collapse_score'] = self._detect_mode_collapse(synthetic_data)
        
        if real_data is not None:
            # Coverage: how well synthetic data covers real data space
            metrics['coverage_score'] = self._compute_coverage(real_data, synthetic_data)
            
            # Precision: how much synthetic data lies within real data manifold
            metrics['precision_score'] = self._compute_precision(real_data, synthetic_data)
        
        return metrics
    
    def _compute_pairwise_distances(self, data: np.ndarray) -> np.ndarray:
        """Compute pairwise L2 distances between samples."""
        n_samples = len(data)
        distances = []
        
        for i in range(n_samples):
            for j in range(i + 1, n_samples):
                dist = np.linalg.norm(data[i] - data[j])
                distances.append(dist)
        
        return np.array(distances)
    
    def _compute_nearest_neighbor_distances(self, data: np.ndarray) -> np.ndarray:
        """Compute nearest neighbor distances."""
        nn = NearestNeighbors(n_neighbors=2)  # 2 because first neighbor is itself
        nn.fit(data)
        distances, _ = nn.kneighbors(data)
        return distances[:, 1]  # Return distances to nearest neighbors (exclude self)
    
    def _detect_mode_collapse(self, data: np.ndarray, threshold: float = 0.01) -> float:
        """Detect mode collapse by analyzing sample similarity."""
        nn_distances = self._compute_nearest_neighbor_distances(data)
        collapsed_samples = np.sum(nn_distances < threshold)
        return collapsed_samples / len(data)
    
    def _compute_coverage(self, real_data: np.ndarray, synthetic_data: np.ndarray, k: int = 3) -> float:
        """Compute coverage score: fraction of real samples that have synthetic neighbors."""
        nn = NearestNeighbors(n_neighbors=k)
        nn.fit(synthetic_data)
        distances, _ = nn.kneighbors(real_data)
        
        # Coverage: fraction of real samples with close synthetic neighbors
        threshold = np.percentile(distances.flatten(), 90)
        covered = np.sum(distances[:, 0] < threshold)
        return covered / len(real_data)
    
    def _compute_precision(self, real_data: np.ndarray, synthetic_data: np.ndarray, k: int = 3) -> float:
        """Compute precision score: fraction of synthetic samples that have real neighbors."""
        nn = NearestNeighbors(n_neighbors=k)
        nn.fit(real_data)
        distances, _ = nn.kneighbors(synthetic_data)
        
        # Precision: fraction of synthetic samples with close real neighbors
        threshold = np.percentile(distances.flatten(), 90)
        precise = np.sum(distances[:, 0] < threshold)
        return precise / len(synthetic_data)
    
    # ========================================
    # 6. COMPREHENSIVE EVALUATION
    # ========================================
    
    def evaluate_comprehensive(self, 
                             real_data: np.ndarray,
                             synthetic_data: np.ndarray,
                             reconstructed_data: Optional[np.ndarray] = None) -> Dict[str, Dict[str, float]]:
        """
        Perform comprehensive evaluation of synthetic ABR data.
        
        Args:
            real_data: Real ABR waveforms
            synthetic_data: Synthetic ABR waveforms
            reconstructed_data: Optional reconstructed data from autoencoder
        
        Returns:
            Comprehensive metrics dictionary
        """
        logger.info("Starting comprehensive ABR synthetic data evaluation...")
        
        all_metrics = {}
        
        # 1. Distributional metrics
        logger.info("Computing distributional metrics...")
        all_metrics['distributional'] = self.compute_distributional_metrics(
            real_data, synthetic_data
        )
        
        # 2. Frequency domain metrics
        logger.info("Computing frequency domain metrics...")
        all_metrics['frequency'] = self.compute_frequency_metrics(
            real_data, synthetic_data
        )
        
        # 3. ABR-specific clinical metrics
        logger.info("Computing ABR clinical metrics...")
        all_metrics['clinical'] = self.compute_abr_clinical_metrics(
            real_data, synthetic_data
        )
        
        # 4. Diversity metrics
        logger.info("Computing diversity metrics...")
        all_metrics['diversity'] = self.compute_diversity_metrics(
            synthetic_data, real_data
        )
        
        # 5. Reconstruction metrics (if available)
        if reconstructed_data is not None:
            logger.info("Computing reconstruction metrics...")
            all_metrics['reconstruction'] = self.compute_reconstruction_metrics(
                real_data, reconstructed_data
            )
        
        # 6. Compute overall quality score
        all_metrics['overall'] = self._compute_overall_score(all_metrics)
        
        logger.info("Comprehensive evaluation completed!")
        return all_metrics
    
    def _compute_overall_score(self, metrics: Dict[str, Dict[str, float]]) -> Dict[str, float]:
        """Compute overall quality scores."""
        overall = {}
        
        # Weighted combination of key metrics
        weights = {
            'distributional_quality': 0.3,
            'frequency_quality': 0.2,
            'clinical_quality': 0.3,
            'diversity_quality': 0.2
        }
        
        # Normalize and combine metrics (simplified approach)
        if 'distributional' in metrics:
            # Lower is better for distributional metrics
            dist_score = 1.0 / (1.0 + metrics['distributional']['wasserstein_distance'])
            overall['distributional_quality'] = dist_score
        
        if 'frequency' in metrics:
            # Higher correlation is better
            freq_score = max(0, metrics['frequency']['psd_correlation'])
            overall['frequency_quality'] = freq_score
        
        if 'clinical' in metrics:
            # Higher morphological similarity is better
            clinical_score = max(0, metrics['clinical']['morphological_similarity'])
            overall['clinical_quality'] = clinical_score
        
        if 'diversity' in metrics:
            # Balance between diversity and coverage
            diversity_score = (
                min(1.0, metrics['diversity']['mean_pairwise_distance'] / 10.0) * 0.5 +
                metrics['diversity'].get('coverage_score', 0.5) * 0.5
            )
            overall['diversity_quality'] = diversity_score
        
        # Compute weighted overall score
        overall['overall_quality'] = sum(
            overall.get(key.replace('_quality', '') + '_quality', 0) * weight
            for key, weight in weights.items()
        )
        
        return overall


def create_evaluation_report(metrics: Dict, output_path: str = "outputs/synthetic_data_evaluation.json"):
    """Create and save evaluation report."""
    import json
    
    # Convert numpy types to Python types for JSON serialization
    def convert_types(obj):
        if isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, np.float32) or isinstance(obj, np.float64):
            return float(obj)
        elif isinstance(obj, np.int32) or isinstance(obj, np.int64):
            return int(obj)
        elif isinstance(obj, dict):
            return {key: convert_types(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [convert_types(item) for item in obj]
        else:
            return obj
    
    metrics_serializable = convert_types(metrics)
    
    with open(output_path, 'w') as f:
        json.dump(metrics_serializable, f, indent=2)
    
    print(f"Evaluation report saved to {output_path}")


if __name__ == "__main__":
    # Example usage
    print("ABR Synthetic Data Evaluation Metrics Guide")
    print("=" * 50)
    
    print("\n📊 Available Metric Categories:")
    print("1. Reconstruction Quality Metrics")
    print("   - MSE, RMSE, MAE, PSNR")
    print("   - Correlation coefficients")
    print("   - Structural similarity")
    
    print("\n2. Distributional Similarity Metrics")
    print("   - Wasserstein distance")
    print("   - Kolmogorov-Smirnov test")
    print("   - Jensen-Shannon divergence")
    print("   - Maximum Mean Discrepancy (MMD)")
    
    print("\n3. Frequency Domain Metrics")
    print("   - Power spectral density comparison")
    print("   - Spectral centroid difference")
    print("   - Bandwidth comparison")
    
    print("\n4. ABR-Specific Clinical Metrics")
    print("   - Wave I, III, V latency accuracy")
    print("   - Amplitude preservation")
    print("   - Morphological similarity")
    
    print("\n5. Diversity and Coverage Metrics")
    print("   - Intra-class diversity")
    print("   - Mode collapse detection")
    print("   - Coverage and precision scores")
    
    print("\n🎯 Recommended Best Practices:")
    print("- Use multiple metric categories for comprehensive evaluation")
    print("- Focus on clinical metrics for medical applications")
    print("- Monitor diversity to avoid mode collapse")
    print("- Validate with domain experts")
    print("- Consider task-specific evaluation criteria") 