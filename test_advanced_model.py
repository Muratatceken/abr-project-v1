#!/usr/bin/env python3
"""
Test script for Advanced CVAE model
===================================

This script tests the Advanced CVAE model functionality including:
- Model creation and parameter counting
- Forward pass with dummy data
- Generation capabilities
- Loss computation
- Comparison with original model
"""

import torch
import numpy as np
import sys
from pathlib import Path

# Add src to path
sys.path.append('src')

def test_model_creation():
    """Test Advanced CVAE model creation."""
    print("üß™ Testing Advanced CVAE Model Creation...")
    
    try:
        from models.advanced_cvae_model import AdvancedConditionalVAE
        
        device = torch.device('cpu')
        model = AdvancedConditionalVAE(
            static_dim=4,
            masked_features_dim=64,
            waveform_latent_dim=64,
            peak_latent_dim=32,
            condition_dim=128,
            hidden_dim=256,
            sequence_length=200,
            use_conditional_prior=True,
            noise_augmentation=0.1
        ).to(device)
        
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        print(f"‚úÖ Model created successfully!")
        print(f"   Total parameters: {total_params:,}")
        print(f"   Trainable parameters: {trainable_params:,}")
        print(f"   Model size: {total_params * 4 / 1e6:.1f} MB")
        
        return model, device
        
    except Exception as e:
        print(f"‚ùå Model creation failed: {e}")
        raise

def create_dummy_batch(batch_size=4, sequence_length=200, device='cpu'):
    """Create dummy batch for testing."""
    print("üìä Creating dummy batch...")
    
    batch = {
        'time_series': torch.randn(batch_size, sequence_length).to(device),
        'static_params': {
            'age': torch.rand(batch_size).to(device) * 80 + 20,  # 20-100 years
            'intensity': torch.rand(batch_size).to(device) * 80 + 20,  # 20-100 dB
            'stimulus_rate': torch.rand(batch_size).to(device) * 90 + 10,  # 10-100 Hz
            'hear_loss': torch.randint(0, 5, (batch_size,)).to(device)
        },
        'latency_data': {
            'I Latancy': torch.rand(batch_size).to(device) * 2 + 1,  # 1-3 ms
            'III Latancy': torch.rand(batch_size).to(device) * 2 + 3,  # 3-5 ms
            'V Latancy': torch.rand(batch_size).to(device) * 2 + 5   # 5-7 ms
        },
        'latency_masks': {
            'I Latancy': torch.randint(0, 2, (batch_size,)).float().to(device),
            'III Latancy': torch.randint(0, 2, (batch_size,)).float().to(device),
            'V Latancy': torch.ones(batch_size).to(device)  # V wave always present
        },
        'amplitude_data': {
            'I Amplitude': torch.rand(batch_size).to(device) * 0.5,
            'III Amplitude': torch.rand(batch_size).to(device) * 0.8,
            'V Amplitude': torch.rand(batch_size).to(device) * 1.0
        },
        'amplitude_masks': {
            'I Amplitude': torch.randint(0, 2, (batch_size,)).float().to(device),
            'III Amplitude': torch.randint(0, 2, (batch_size,)).float().to(device),
            'V Amplitude': torch.ones(batch_size).to(device)  # V wave always present
        }
    }
    
    print(f"‚úÖ Dummy batch created with {batch_size} samples")
    return batch

def test_forward_pass(model, batch):
    """Test forward pass through the model."""
    print("üîÑ Testing Forward Pass...")
    
    try:
        model.eval()
        with torch.no_grad():
            outputs = model(batch)
        
        print("‚úÖ Forward pass successful!")
        print("   Output keys:", list(outputs.keys()))
        
        # Check output shapes
        expected_outputs = [
            'abr_reconstruction', 'peak_predictions', 'generated_static_params',
            'waveform_z', 'peak_z', 'combined_z', 'condition'
        ]
        
        for key in expected_outputs:
            if key in outputs:
                if isinstance(outputs[key], torch.Tensor):
                    print(f"   {key}: {outputs[key].shape}")
                elif isinstance(outputs[key], dict):
                    print(f"   {key}: dict with keys {list(outputs[key].keys())}")
                else:
                    print(f"   {key}: {type(outputs[key])}")
            else:
                print(f"   ‚ö†Ô∏è Missing output: {key}")
        
        return outputs
        
    except Exception as e:
        print(f"‚ùå Forward pass failed: {e}")
        raise

def test_loss_computation(model, batch):
    """Test loss computation."""
    print("üìâ Testing Loss Computation...")
    
    try:
        model.train()
        loss_dict = model.compute_loss(batch)
        
        print("‚úÖ Loss computation successful!")
        print("   Loss components:")
        for key, value in loss_dict.items():
            if isinstance(value, torch.Tensor):
                print(f"   {key}: {value.item():.4f}")
            else:
                print(f"   {key}: {value}")
        
        # Check for NaN values
        has_nan = any(torch.isnan(v).any() if isinstance(v, torch.Tensor) else False 
                     for v in loss_dict.values())
        
        if has_nan:
            print("‚ö†Ô∏è Warning: NaN values detected in loss!")
        else:
            print("‚úÖ No NaN values in loss")
        
        return loss_dict
        
    except Exception as e:
        print(f"‚ùå Loss computation failed: {e}")
        raise

def test_generation(model, batch):
    """Test generation capabilities."""
    print("üé® Testing Generation Capabilities...")
    
    try:
        model.eval()
        
        # Test conditional generation
        print("   Testing conditional generation...")
        with torch.no_grad():
            gen_results_cond = model.generate(
                batch=batch, 
                num_samples=2, 
                use_conditioning=True,
                temperature=1.0
            )
        
        print("   ‚úÖ Conditional generation successful!")
        print(f"   Generated waveforms shape: {gen_results_cond['abr_waveforms'].shape}")
        
        # Test unconditional generation
        print("   Testing unconditional generation...")
        with torch.no_grad():
            gen_results_uncond = model.generate(
                num_samples=3, 
                use_conditioning=False,
                temperature=0.8
            )
        
        print("   ‚úÖ Unconditional generation successful!")
        print(f"   Generated waveforms shape: {gen_results_uncond['abr_waveforms'].shape}")
        
        # Check generated components
        for key, value in gen_results_uncond.items():
            if isinstance(value, torch.Tensor):
                print(f"   {key}: {value.shape}")
            elif isinstance(value, dict):
                print(f"   {key}: dict with keys {list(value.keys())}")
        
        return gen_results_cond, gen_results_uncond
        
    except Exception as e:
        print(f"‚ùå Generation failed: {e}")
        raise

def test_peak_predictions(outputs):
    """Test peak prediction outputs."""
    print("üîç Testing Peak Predictions...")
    
    try:
        if 'peak_predictions' in outputs:
            peak_preds = outputs['peak_predictions']
            
            print("‚úÖ Peak predictions found!")
            print("   Peak prediction components:")
            for key, value in peak_preds.items():
                if isinstance(value, torch.Tensor):
                    print(f"   {key}: {value.shape}, range: [{value.min():.3f}, {value.max():.3f}]")
            
            # Check presence probabilities
            if 'presence_probs' in peak_preds:
                probs = peak_preds['presence_probs']
                print(f"   Peak presence probabilities: {probs.mean(dim=0).tolist()}")
        else:
            print("‚ö†Ô∏è No peak predictions found in outputs")
            
    except Exception as e:
        print(f"‚ùå Peak prediction test failed: {e}")

def test_static_parameter_generation(outputs):
    """Test static parameter generation."""
    print("üìä Testing Static Parameter Generation...")
    
    try:
        if 'generated_static_params' in outputs:
            static_params = outputs['generated_static_params']
            
            print("‚úÖ Static parameter generation found!")
            print("   Generated parameters:")
            for key, value in static_params.items():
                if isinstance(value, torch.Tensor):
                    print(f"   {key}: range [{value.min():.2f}, {value.max():.2f}], mean {value.mean():.2f}")
        else:
            print("‚ö†Ô∏è No static parameter generation found in outputs")
            
    except Exception as e:
        print(f"‚ùå Static parameter generation test failed: {e}")

def compare_with_original_model(batch):
    """Compare with original CVAE model."""
    print("üîÑ Comparing with Original CVAE Model...")
    
    try:
        from models.cvae_model import ConditionalVAEWithMasking
        
        device = batch['time_series'].device
        original_model = ConditionalVAEWithMasking(
            static_dim=4,
            masked_features_dim=64,
            latent_dim=128,
            condition_dim=128,
            hidden_dim=256,
            sequence_length=200,
            beta=1.0
        ).to(device)
        
        original_params = sum(p.numel() for p in original_model.parameters())
        
        print(f"‚úÖ Original model created for comparison")
        print(f"   Original model parameters: {original_params:,}")
        
        # Test forward pass
        original_model.eval()
        with torch.no_grad():
            original_outputs = original_model(batch)
        
        print("‚úÖ Original model forward pass successful!")
        print("   Original output keys:", list(original_outputs.keys()))
        
        return original_model, original_outputs
        
    except Exception as e:
        print(f"‚ùå Original model comparison failed: {e}")
        return None, None

def main():
    """Main test function."""
    print("üß¨ Advanced CVAE Model Test Suite")
    print("=" * 50)
    
    try:
        # Test 1: Model Creation
        model, device = test_model_creation()
        print()
        
        # Test 2: Create dummy data
        batch = create_dummy_batch(batch_size=4, device=device)
        print()
        
        # Test 3: Forward pass
        outputs = test_forward_pass(model, batch)
        print()
        
        # Test 4: Loss computation
        loss_dict = test_loss_computation(model, batch)
        print()
        
        # Test 5: Generation
        gen_cond, gen_uncond = test_generation(model, batch)
        print()
        
        # Test 6: Peak predictions
        test_peak_predictions(outputs)
        print()
        
        # Test 7: Static parameter generation
        test_static_parameter_generation(outputs)
        print()
        
        # Test 8: Compare with original
        original_model, original_outputs = compare_with_original_model(batch)
        print()
        
        # Summary
        print("üéâ ALL TESTS PASSED!")
        print("=" * 50)
        print("‚úÖ Advanced CVAE model is working correctly!")
        print("‚úÖ All components (hierarchical latents, conditional priors, FiLM, etc.) functional")
        print("‚úÖ Generation capabilities verified")
        print("‚úÖ Multi-task learning components working")
        print()
        print("üöÄ The model is ready for training!")
        
        return True
        
    except Exception as e:
        print(f"\n‚ùå TEST FAILED: {e}")
        print("Please check the error above and fix any issues.")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 